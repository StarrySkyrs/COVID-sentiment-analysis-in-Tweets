{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled49.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction set up"
      ],
      "metadata": {
        "id": "vN5c5FLY8Kw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG5bUM3suYLH",
        "outputId": "3c6bdcf1-92af-4879-a5c5-7dd616b7d7ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uUyhD80q2K5J"
      },
      "outputs": [],
      "source": [
        "# required imports\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import spacy\n",
        "import tensorflow\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "# load spacy module\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.optimization import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3jKdtQpmp-k",
        "outputId": "6fc1dce5-f24d-484b-eeb2-0b40e747a62c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "# For transformers v4.x+:\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD6AO7Cb9J5Z",
        "outputId": "36179e8b-6169-4c35-8015-907e8cdf3fbd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "emoji is not installed, thus not converting emoticons or emojis into text. Please install emoji: pip3 install emoji\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bertweet_cls(nn.Module):\n",
        "\n",
        "    def __init__(self, lab2ind, model_path, hidden_size):\n",
        "        super(Bertweet_cls, self).__init__()\n",
        "        self.model_path = model_path\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bert_model = AutoModel.from_pretrained(model_path, output_hidden_states=True, output_attentions=True)\n",
        "        \n",
        "        self.label_num = len(lab2ind)\n",
        "        \n",
        "        self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.label_num)\n",
        "\n",
        "    def forward(self, bert_ids, bert_mask):\n",
        "        outputs = self.bert_model(input_ids=bert_ids, attention_mask = bert_mask)\n",
        "        pooler_output = outputs['pooler_output']\n",
        "        attentions = outputs['attentions']\n",
        "        \n",
        "        x = self.dense(pooler_output)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        fc_output = self.fc(x)\n",
        "\n",
        "        return fc_output, attentions"
      ],
      "metadata": {
        "id": "_6p7doAW2U0x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab2ind_sent = {0: 0, 1: 1, 2: 2}\n",
        "#lab2sent_ind = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "lab2ind_emoji = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 9:9, 10:10, 11:11, 12:12, 13:13, 14:14, 15:15, 16:16, 17:17, 18:18, 19:19}"
      ],
      "metadata": {
        "id": "MfgGR6L-9C8Y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/MyDrive/Colab Notebooks/ckpt_BERTweet/BERT_sentiment3.pt',map_location=torch.device('cpu'))\n",
        "model_sentiment = Bertweet_cls(lab2ind_sent, \"vinai/bertweet-base\", 768).to(device)\n",
        "model_sentiment.load_state_dict(model['state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9nGzhD1xJ6H",
        "outputId": "2b15c055-295f-46a1-93be-7db46e240920"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sententce_prepocess(content, tokenizer, max_len = 64):\n",
        "    \"\"\"\n",
        "    content: list of string. Each string is a sample. We only include one sample in this list.\n",
        "    tokenizer: BertTokenizerFast\n",
        "    \"\"\"\n",
        "    #### REF START ####\n",
        "\n",
        "    # We need to add a special token at the beginning for BERT to work properly.\n",
        "    content = [\"[CLS] \" + text for text in content]\n",
        "\n",
        "    # Import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary.\n",
        "    tokenized_texts = [tokenizer.tokenize(text) for text in content]\n",
        "    \n",
        "    # if the sequence is longer the maximal length, we truncate it to the pre-defined maximal length\n",
        "    tokenized_texts = [ text[:max_len+1] for text in tokenized_texts]\n",
        "\n",
        "    # We also need to add a special token at the end.\n",
        "    tokenized_texts = [ text+['[SEP]'] for text in tokenized_texts]\n",
        "    #print (\"Tokenize the first sentence:\\n\",tokenized_texts[0])\n",
        "    \n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    #print (\"Index numbers of the first sentence:\\n\",input_ids[0])\n",
        "\n",
        "    # Pad our input seqeunce to the fixed length (i.e., max_len) with index of [PAD] token\n",
        "    pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=max_len+2, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "    #print (\"Index numbers of the first sentence after padding:\\n\",input_ids[0])\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for pad tokens\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "    #### REF END ####\n",
        "\n",
        "    return tokenized_texts, inputs, masks"
      ],
      "metadata": {
        "id": "7Z4x0aJSS6hH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"When \\u2066@nbcsnl\\u2069 hits the truth about \\u2066@cvspharmacy\\u2069 right on the head.\\n\\nThe only thing longer than a CVS receipt is the time it takes to sort your way through a #Covid vaccine sign-up website. https://t.co/K37bxJdnSl\""
      ],
      "metadata": {
        "id": "vo9zvugRmlCB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_pred(sentence, tokenizer):\n",
        "  # return the prediction of the given twitter context and the confidence prob\n",
        "  tokenized_texts, input_ids, masks = sententce_prepocess([sentence], tokenizer)\n",
        "  input_ids, masks = input_ids.to(device), masks.to(device)\n",
        "  outputs,_ = model_sentiment(input_ids, masks)\n",
        "  softmax_fn = nn.Softmax(dim=1)\n",
        "  outputs = softmax_fn(outputs)\n",
        "  probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "\n",
        "  return lab2ind_sent[predicted[0].item()], probabilities"
      ],
      "metadata": {
        "id": "qg7nbV-Br1bL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred, prob = sent_pred(sentence, tokenizer)\n",
        "print(\"Sentence = \", sentence)\n",
        "print(\"The prediction is: \", pred)\n",
        "print(\"Confidence: %.4f\" % prob.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76TTb2UqtzPm",
        "outputId": "c9928027-4ca7-42e9-a46f-bce48cab6450"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence =  When ⁦@nbcsnl⁩ hits the truth about ⁦@cvspharmacy⁩ right on the head.\n",
            "\n",
            "The only thing longer than a CVS receipt is the time it takes to sort your way through a #Covid vaccine sign-up website. https://t.co/K37bxJdnSl\n",
            "The prediction is:  0\n",
            "Confidence: 0.6809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting on mask corpus"
      ],
      "metadata": {
        "id": "vGCZHjRi79nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masks_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Bertweet/Data/clean_masks_twitter.csv\")\n",
        "masks_t = masks_df[\"tweet_text\"]\n",
        "masks_df.head(3)"
      ],
      "metadata": {
        "id": "uwAUJRU2kY3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "6be26512-e70e-42b4-9ec6-8e6cf922fe5d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0            author_id created_at             tweet_id  \\\n",
              "0           0   835967581693612033    2021-07  1421619622445469697   \n",
              "1           1   825765275853344773    2021-07  1421619085876547586   \n",
              "2           2  1412770891335864320    2021-07  1421617357051596804   \n",
              "\n",
              "                                          tweet_text  CNN_prediction  \\\n",
              "0  The manipulative, politically opportune lying ...             NaN   \n",
              "1  @user Someone should introduce a bill mandatin...             NaN   \n",
              "2  Just wear a friggin #mask we will never #MakeA...             NaN   \n",
              "\n",
              "   CNN_confidence  BERTweet_prediction  BERTweet_confidence  \\\n",
              "0             NaN                  NaN                  NaN   \n",
              "1             NaN                  NaN                  NaN   \n",
              "2             NaN                  NaN                  NaN   \n",
              "\n",
              "   BERTweet_fine-tuned_prediction  BERTweet_fine-tuned_confidence  \\\n",
              "0                             NaN                             NaN   \n",
              "1                             NaN                             NaN   \n",
              "2                             NaN                             NaN   \n",
              "\n",
              "   final_prediction  \n",
              "0               NaN  \n",
              "1               NaN  \n",
              "2               NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b42e9aaf-510a-424d-b1d6-bad4b154c60f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>author_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>CNN_prediction</th>\n",
              "      <th>CNN_confidence</th>\n",
              "      <th>BERTweet_prediction</th>\n",
              "      <th>BERTweet_confidence</th>\n",
              "      <th>BERTweet_fine-tuned_prediction</th>\n",
              "      <th>BERTweet_fine-tuned_confidence</th>\n",
              "      <th>final_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>835967581693612033</td>\n",
              "      <td>2021-07</td>\n",
              "      <td>1421619622445469697</td>\n",
              "      <td>The manipulative, politically opportune lying ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>825765275853344773</td>\n",
              "      <td>2021-07</td>\n",
              "      <td>1421619085876547586</td>\n",
              "      <td>@user Someone should introduce a bill mandatin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1412770891335864320</td>\n",
              "      <td>2021-07</td>\n",
              "      <td>1421617357051596804</td>\n",
              "      <td>Just wear a friggin #mask we will never #MakeA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b42e9aaf-510a-424d-b1d6-bad4b154c60f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b42e9aaf-510a-424d-b1d6-bad4b154c60f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b42e9aaf-510a-424d-b1d6-bad4b154c60f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id, text in enumerate(masks_t):\n",
        "  pred, prob = sent_pred(text, tokenizer)\n",
        "  masks_df.loc[id, \"BERTweet_prediction\"] = pred\n",
        "  masks_df.loc[id, \"BERTweet_confidence\"] = prob.item()"
      ],
      "metadata": {
        "id": "dI6bDCCf8_BW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting on vaccine corpus"
      ],
      "metadata": {
        "id": "1kAzzY7B9IXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vaccine_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Bertweet/Data/clean_vaccines_twitter.csv\")\n",
        "vaccine_t = vaccine_df[\"tweet_text\"]"
      ],
      "metadata": {
        "id": "mytIlupn9K-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a999502-db97-41a4-e21b-4f9718bc2bf5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id, text in enumerate(vaccine_t):\n",
        "  pred, prob = sent_pred(text, tokenizer)\n",
        "  vaccine_df.loc[id, \"BERTweet_prediction\"] = pred\n",
        "  vaccine_df.loc[id, \"BERTweet_confidence\"] = prob.item()"
      ],
      "metadata": {
        "id": "d650VEKWCZTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}