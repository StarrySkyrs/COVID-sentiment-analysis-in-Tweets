{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMsJXv7n8I47",
        "outputId": "6f77de14-a1cc-4a2e-e434-6e4e78c1b7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLexL9Nz8OOb",
        "outputId": "af5c155e-a23f-41ad-9bc7-bd084f99ad6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=65f1b096ac5139aca60407798d7a1353d77938e86dbf0e74dc3372ab43ae92dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_n1iyvgl/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import Field, LabelField\n",
        "from torchtext.legacy.data import TabularDataset\n",
        "from torchtext.legacy.data import Iterator, BucketIterator"
      ],
      "metadata": {
        "id": "M4bvHizt8TUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "# from torchtext.data import Field, LabelField # For torch<=0.8.0, the importing of functions should be `from torchtext.data`\n",
        "# from torchtext.data import TabularDataset\n",
        "# from torchtext.data import Iterator, BucketIterator\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DsMqNxF8UMT",
        "outputId": "9bac5d46-0481-420b-9e6b-20b710848d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_en = en_core_web_lg.load()\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "# stopwords = spacy_en.Defaults.stop_words  "
      ],
      "metadata": {
        "id": "bRnid5pK8XxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=True, batch_first = True)\n",
        "LABEL = Field(sequential=False, unk_token = None)\n",
        "\n",
        "train, val = TabularDataset.splits(\n",
        "               path=\"./drive/My Drive/CNN/\", # the root directory where the data lies\n",
        "               train='train.tsv', validation=\"dev.tsv\", # file names\n",
        "               format='tsv',\n",
        "               skip_header=False, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=[(None, None),('label', LABEL), ('tweet', TEXT)])\n",
        "test = TabularDataset.splits(\n",
        "               path=\"/content/drive/MyDrive/CNN/\", # the root directory where the data lies\n",
        "               test=\"tweets_test_masks.tsv\", # file names\n",
        "               format='tsv',\n",
        "               skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=[(None, None), ('tweet', TEXT), ('label', LABEL)])"
      ],
      "metadata": {
        "id": "VWMw34GV8Wqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "# specifying the zip file name\n",
        "file_name = \"./drive/My Drive/CNN/emb.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "  \n",
        "    # extracting all the files\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kei5utDA8hbj",
        "outputId": "e1c027ea-83df-47f5-ec24-f38e101dced7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "glove.twitter.27B.100d.txt                     2015-12-22 16:04:54   1021671926\n",
            "glove.twitter.27B.200d.txt                     2015-12-22 16:04:54   2057595650\n",
            "glove.twitter.27B.25d.txt                      2015-12-22 16:04:54    257699930\n",
            "glove.twitter.27B.50d.txt                      2015-12-22 16:04:54    510889212\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.vocab as vocab\n",
        "loaded_vectors = torchtext.vocab.Vectors('/content/drive/MyDrive/CNN/glove.twitter.27B.200d.txt')\n",
        "TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi), unk_init = torch.Tensor.normal_)\n",
        "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
        "LABEL.build_vocab(train)\n",
        "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
        "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D8fSbyF8klz",
        "outputId": "02bed868-973e-41a6-c697-f54812f994f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size of TEXT: 37888\n",
            "Vocabulary size of LABEL: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy import data\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, val, test), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.tweet), \n",
        "    sort=True,\n",
        "    sort_within_batch=True, \n",
        "    device = device)"
      ],
      "metadata": {
        "id": "P9ykj1eV9Dn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return F.softmax(self.fc(cat), dim=1)"
      ],
      "metadata": {
        "id": "fEI6VtQh9a16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 200\n",
        "N_FILTERS = 200\n",
        "FILTER_SIZES = [3,4,5,6,7]\n",
        "OUTPUT_DIM = 3\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "metadata": {
        "id": "6YBkBUpv-grZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DrhgY6Y-oV0",
        "outputId": "cd988fea-c4e0-44e5-b850-3e70856303b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(37888, 200, padding_idx=1)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 200, kernel_size=(3, 200), stride=(1, 1))\n",
              "    (1): Conv2d(1, 200, kernel_size=(4, 200), stride=(1, 1))\n",
              "    (2): Conv2d(1, 200, kernel_size=(5, 200), stride=(1, 1))\n",
              "    (3): Conv2d(1, 200, kernel_size=(6, 200), stride=(1, 1))\n",
              "    (4): Conv2d(1, 200, kernel_size=(7, 200), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=1000, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "DAXGPOAe-qh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "wchdKojo-z54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "7Nc6wjPw-3OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        batch_input, labels = batch.tweet, batch.label\n",
        "        batch_input = batch_input.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_input)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.cpu().item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            batch_input, labels = batch.tweet, batch.label\n",
        "            batch_input = batch_input.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch_input)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "metadata": {
        "id": "O-rGryZuDJGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPOCH = 15\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/CNN/CNN_DEEP_TEXT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vrluHl7DKtT",
        "outputId": "7e015a06-936c-4acd-9490-a2a83ed2acf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   7%|▋         | 1/15 [01:57<27:28, 117.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [1/15], Train Loss: 0.7313, Validation Loss: 0.9898, Validation Accuracy: 0.5440, Validation F1: 0.4877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 2/15 [03:49<24:47, 114.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [2/15], Train Loss: 0.6794, Validation Loss: 0.9974, Validation Accuracy: 0.5299, Validation F1: 0.5144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 3/15 [05:41<22:37, 113.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [3/15], Train Loss: 0.6426, Validation Loss: 0.9976, Validation Accuracy: 0.5331, Validation F1: 0.5167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 4/15 [07:33<20:38, 112.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [4/15], Train Loss: 0.6189, Validation Loss: 0.9873, Validation Accuracy: 0.5489, Validation F1: 0.5341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 5/15 [09:24<18:42, 112.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [5/15], Train Loss: 0.6000, Validation Loss: 0.9984, Validation Accuracy: 0.5352, Validation F1: 0.5107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 6/15 [11:16<16:48, 112.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [6/15], Train Loss: 0.5884, Validation Loss: 0.9979, Validation Accuracy: 0.5363, Validation F1: 0.4993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 7/15 [13:08<14:55, 111.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [7/15], Train Loss: 0.5828, Validation Loss: 0.9931, Validation Accuracy: 0.5436, Validation F1: 0.5292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 8/15 [14:57<12:57, 111.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [8/15], Train Loss: 0.5784, Validation Loss: 0.9971, Validation Accuracy: 0.5386, Validation F1: 0.5248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 9/15 [16:47<11:03, 110.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [9/15], Train Loss: 0.5763, Validation Loss: 1.0106, Validation Accuracy: 0.5267, Validation F1: 0.5178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 10/15 [18:36<09:10, 110.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [10/15], Train Loss: 0.5746, Validation Loss: 0.9856, Validation Accuracy: 0.5520, Validation F1: 0.5302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 11/15 [20:29<07:24, 111.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [11/15], Train Loss: 0.5734, Validation Loss: 0.9867, Validation Accuracy: 0.5505, Validation F1: 0.5354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 12/15 [22:19<05:32, 110.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [12/15], Train Loss: 0.5719, Validation Loss: 0.9880, Validation Accuracy: 0.5514, Validation F1: 0.5339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 13/15 [24:09<03:40, 110.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [13/15], Train Loss: 0.5714, Validation Loss: 0.9863, Validation Accuracy: 0.5560, Validation F1: 0.5269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  93%|█████████▎| 14/15 [25:58<01:50, 110.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [14/15], Train Loss: 0.5709, Validation Loss: 0.9962, Validation Accuracy: 0.5436, Validation F1: 0.5302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 15/15 [27:48<00:00, 111.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [15/15], Train Loss: 0.5703, Validation Loss: 0.9817, Validation Accuracy: 0.5601, Validation F1: 0.5346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}