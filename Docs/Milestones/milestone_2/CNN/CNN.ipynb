{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si2dq37WgEhU",
        "outputId": "5297e88b-17ea-474e-a241-5b6af8742e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5ASZjAJgu9z",
        "outputId": "2a29ca37-12da-48e0-9fbd-c93768fc7758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=389ed3374c2ab1843345ef0ceeb7c3e7f527aaa5d4181143bcf07d60adda2106\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-32l0fh8w/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "WU7n8BmAi_sJ",
        "outputId": "707a0b5e-d054-4ea9-b0b2-119265bd25e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.5)\n",
            "Collecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:39tcmalloc: large alloc 1147494400 bytes == 0x55b597056000 @  0x7f58d3a4d615 0x55b55de7617c 0x55b55df5647a 0x55b55de78f9d 0x55b55df6ad4d 0x55b55deecec8 0x55b55dee7a2e 0x55b55de7a88a 0x55b55deecd30 0x55b55dee7a2e 0x55b55de7a88a 0x55b55dee9719 0x55b55df6bb76 0x55b55dee8d95 0x55b55df6bb76 0x55b55dee8d95 0x55b55df6bb76 0x55b55dee8d95 0x55b55de7ace9 0x55b55debe579 0x55b55de79902 0x55b55deecc4d 0x55b55dee7a2e 0x55b55de7a88a 0x55b55dee9719 0x55b55dee7a2e 0x55b55de7a88a 0x55b55dee88f6 0x55b55de7a7aa 0x55b55dee8b4f 0x55b55dee7a2e\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0\n",
            "    Uninstalling torch-1.11.0:\n",
            "      Successfully uninstalled torch-1.11.0\n",
            "Successfully installed torch-1.10.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLtqC39GivER"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy.data import Field, LabelField\n",
        "from torchtext.legacy.data import TabularDataset\n",
        "from torchtext.legacy.data import Iterator, BucketIterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdaPNweUg8ab",
        "outputId": "d7d2a705-7bd2-49cf-bdc2-6d060359245c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "# from torchtext.data import Field, LabelField # For torch<=0.8.0, the importing of functions should be `from torchtext.data`\n",
        "# from torchtext.data import TabularDataset\n",
        "# from torchtext.data import Iterator, BucketIterator\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7y2CJT1hMdb"
      },
      "outputs": [],
      "source": [
        "spacy_en = en_core_web_lg.load()\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "stopwords = spacy_en.Defaults.stop_words    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "rjmAfZmXhXib"
      },
      "outputs": [],
      "source": [
        "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=True)\n",
        "LABEL = Field(sequential=False, unk_token = None)\n",
        "\n",
        "train, val = TabularDataset.splits(\n",
        "               path=\"./drive/My Drive/CNN/\", # the root directory where the data lies\n",
        "               train='train.tsv', validation=\"dev.tsv\", # file names\n",
        "               format='tsv',\n",
        "               skip_header=False, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=[(None, None),('label', LABEL), ('tweet', TEXT)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = TabularDataset.splits(\n",
        "               path=\"/content/drive/MyDrive/CNN/\", # the root directory where the data lies\n",
        "               test=\"test_masks.tsv\", # file names\n",
        "               format='tsv',\n",
        "               skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=[(None, None), ('tweet', TEXT), ('label', LABEL)])"
      ],
      "metadata": {
        "id": "-MMjqvUZnYQ3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test[0]"
      ],
      "metadata": {
        "id": "6L4yZsziazdg"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY233hxgR94y",
        "outputId": "94d15188-31bb-40c4-af25-978958e88783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "glove.twitter.27B.100d.txt                     2015-12-22 16:04:54   1021671926\n",
            "glove.twitter.27B.200d.txt                     2015-12-22 16:04:54   2057595650\n",
            "glove.twitter.27B.25d.txt                      2015-12-22 16:04:54    257699930\n",
            "glove.twitter.27B.50d.txt                      2015-12-22 16:04:54    510889212\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# import torchtext.vocab as vocab\n",
        "# custom_embeddings = vocab.Vectors(name = root_path + 'glove.twitter.27B.200d.txt',\n",
        "#                                   cache = 'custom_embeddings',\n",
        "#                                   unk_init = torch.Tensor.normal_)\n",
        "from zipfile import ZipFile\n",
        "  \n",
        "# specifying the zip file name\n",
        "file_name = \"./drive/My Drive/CNN/emb.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "  \n",
        "    # extracting all the files\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clBKGQaPnBoS",
        "outputId": "1025169e-3cbf-4ee6-bb26-eddfcdb8c2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size of TEXT: 37888\n",
            "Vocabulary size of LABEL: 3\n"
          ]
        }
      ],
      "source": [
        "# pre_trained_vector_type = '/content/drive/MyDrive/CNN/glove.twitter.27B.200d.txt'\n",
        "import torchtext.vocab as vocab\n",
        "loaded_vectors = torchtext.vocab.Vectors('/content/drive/MyDrive/CNN/glove.twitter.27B.200d.txt')\n",
        "# fine_trained_vectors = vocab.Vectors('/content/drive/MyDrive/CNN/glove.twitter.27B.200d.txt')\n",
        "# TEXT.build_vocab(train, vectors=fine_trained_vectors)\n",
        "TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
        "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
        "LABEL.build_vocab(train)\n",
        "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
        "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train, val, test), \n",
        "    batch_size = 32,\n",
        "    sort_key=lambda x: len(x.tweet), \n",
        "    sort=True,\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "-89dtMJQx3bW"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd_SNPhNX3gr",
        "outputId": "b1366097-74fa-410f-d313-47959aa42c4d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKZtx7HUoEep"
      },
      "outputs": [],
      "source": [
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
        "        '''\n",
        "        vocabulary_size: vocabulary size\n",
        "        embedding_dim: word embedding size\n",
        "        output_size: number of classes in prediction\n",
        "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
        "        region_sizes: height of kernels of convolutional layers\n",
        "        dropout: dropout rate\n",
        "        '''\n",
        "        super(CNN_Text, self).__init__()\n",
        "        # the size of input channel is 1.\n",
        "        Ci = 1\n",
        "        \n",
        "        # word embedding layer\n",
        "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim )\n",
        "        \n",
        "        # convolution with kernels\n",
        "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
        "        \n",
        "        # a dropout layer\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        \n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input x  [sequence length, batch size]\n",
        "        \n",
        "        input_embeddings = self.embeddings(x)  \n",
        "        # (batch size, word_sequence, embedding_dim) word embedding\n",
        "\n",
        "        input_embeddings = input_embeddings.permute(1,0,2)\n",
        "        input_embeddings = input_embeddings.unsqueeze(1)\n",
        "        #  [batch size, number of channel is one, sequence length, embeeding size]\n",
        "\n",
        "        # convolutional layers\n",
        "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
        "        \n",
        "        # to get the maximum value of filtered tensor\n",
        "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
        "        \n",
        "        concat_list = torch.cat(max_pooling_outputs, 1) # concatenate representations\n",
        "        \n",
        "        drop_output = self.dropout(concat_list)  # add drop layer\n",
        "        \n",
        "        fc1_output = self.fc(drop_output)  # get the fc1 using a fully connected layer\n",
        "        \n",
        "        final_output = F.softmax(fc1_output,dim=1)\n",
        "        \n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIJHsmpFRt-R"
      },
      "outputs": [],
      "source": [
        "class CNN_BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super(CNN_BiLSTM, self).__init__()\n",
        "        self.args = args\n",
        "        self.hidden_dim = args.lstm_hidden_dim\n",
        "        self.num_layers = args.lstm_num_layers\n",
        "        V = args.embed_num\n",
        "        D = args.embed_dim\n",
        "        C = args.class_num\n",
        "        self.C = C\n",
        "        Ci = 1\n",
        "        Co = args.kernel_num\n",
        "        Ks = args.kernel_sizes\n",
        "        self.embed = nn.Embedding(V, D, padding_idx=args.paddingId)\n",
        "        # pretrained  embedding\n",
        "        if args.word_Embedding:\n",
        "            self.embed.weight.data.copy_(args.pretrained_weight)\n",
        "\n",
        "        # CNN\n",
        "        self.convs1 = [nn.Conv2d(Ci, Co, (K, D), padding=(K//2, 0), stride=1) for K in Ks]\n",
        "        print(self.convs1)\n",
        "        # for cnn cuda\n",
        "        # if self.args.cuda is True:\n",
        "        #     for conv in self.convs1:\n",
        "        #         conv = conv.cuda()\n",
        "\n",
        "        # BiLSTM\n",
        "        self.bilstm = nn.LSTM(D, self.hidden_dim, num_layers=self.num_layers, dropout=args.dropout, bidirectional=True, bias=True)\n",
        "\n",
        "        # linear\n",
        "        L = len(Ks) * Co + self.hidden_dim * 2\n",
        "        self.hidden2label1 = nn.Linear(L, L // 2)\n",
        "        self.hidden2label2 = nn.Linear(L // 2, C)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embed(x)\n",
        "\n",
        "        # CNN\n",
        "        cnn_x = embed\n",
        "        cnn_x = torch.transpose(cnn_x, 0, 1)\n",
        "        cnn_x = cnn_x.unsqueeze(1)\n",
        "        cnn_x = [F.relu(conv(cnn_x)).squeeze(3) for conv in self.convs1]  # [(N,Co,W), ...]*len(Ks)\n",
        "        cnn_x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in cnn_x]  # [(N,Co), ...]*len(Ks)\n",
        "        cnn_x = torch.cat(cnn_x, 1)\n",
        "        cnn_x = self.dropout(cnn_x)\n",
        "\n",
        "        # BiLSTM\n",
        "        bilstm_x = embed.view(len(x), embed.size(1), -1)\n",
        "        bilstm_out, _ = self.bilstm(bilstm_x)\n",
        "        bilstm_out = torch.transpose(bilstm_out, 0, 1)\n",
        "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
        "        bilstm_out = F.max_pool1d(bilstm_out, bilstm_out.size(2)).squeeze(2)\n",
        "        # bilstm_out = F.tanh(bilstm_out)\n",
        "\n",
        "        # CNN and BiLSTM CAT\n",
        "        cnn_x = torch.transpose(cnn_x, 0, 1)\n",
        "        bilstm_out = torch.transpose(bilstm_out, 0, 1)\n",
        "        cnn_bilstm_out = torch.cat((cnn_x, bilstm_out), 0)\n",
        "        cnn_bilstm_out = torch.transpose(cnn_bilstm_out, 0, 1)\n",
        "\n",
        "        # linear\n",
        "        cnn_bilstm_out = self.hidden2label1(F.tanh(cnn_bilstm_out))\n",
        "        cnn_bilstm_out = self.hidden2label2(F.tanh(cnn_bilstm_out))\n",
        "\n",
        "        # output\n",
        "        logit = cnn_bilstm_out\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQu_y2g1TZEy",
        "outputId": "a65ab599-ac72-472f-af56-315b1206cc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Conv2d(1, 32, kernel_size=(2, 200), stride=(1, 1), padding=(1, 0)), Conv2d(1, 32, kernel_size=(3, 200), stride=(1, 1), padding=(1, 0)), Conv2d(1, 32, kernel_size=(4, 200), stride=(1, 1), padding=(2, 0))]\n"
          ]
        }
      ],
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "# the vocabulary size\n",
        "vocabulary_size = len(TEXT.vocab.stoi) \n",
        "hidden_dim = 512\n",
        "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
        "embedding_dim = 200 \n",
        "num_layers = 2\n",
        "# region size as 2, 3, and 4\n",
        "kernel_sizes = [2,3,4] \n",
        "\n",
        "# the number of kernel in each region size\n",
        "kernels_num = 32 \n",
        "\n",
        "# The dropout rate is set to be 0.5.\n",
        "dropout = 0.2\n",
        "\n",
        "# The output size of labels.\n",
        "output_size = 3\n",
        "\n",
        "# learning rate is set to be 0.01.\n",
        "lr = 0.001        \n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "# The number of iteration is set to be 5.\n",
        "num_epoch = 20 \n",
        "\n",
        "class CNNArgs:\n",
        "  def __init__(self, hidden_dim, num_layers, vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout) -> None:\n",
        "      self.lstm_hidden_dim = hidden_dim\n",
        "      self.lstm_num_layers = num_layers\n",
        "      self.embed_num = vocabulary_size \n",
        "      self.embed_dim = embedding_dim\n",
        "      self.class_num = output_size\n",
        "      self.kernel_num = kernels_num\n",
        "      self.kernel_sizes = kernel_sizes\n",
        "      self.dropout = dropout\n",
        "      self.paddingId = None\n",
        "      self.word_Embedding = None\n",
        "      self.cuda = True\n",
        "\n",
        "\n",
        "args_for_cnn = CNNArgs(hidden_dim, num_layers, vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout)\n",
        "\n",
        "\n",
        "# employ class CNN_Text and assign to cnn\n",
        "model = CNN_BiLSTM(args_for_cnn).to(device)\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embed.weight.data.copy_(pretrained_embeddings)\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embed.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
        "model.embed.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "# loss_func = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        " \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./drive/My Drive/CNN/CNN_LSTM_1.pt')['state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srb8xLIWVou1",
        "outputId": "f4329ff0-68bc-4ef3-bdd2-85ab9a1529bc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in train_iter:\n",
        "#   print(i)"
      ],
      "metadata": {
        "id": "EFnfK2E7WqZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_f1 = evaluate(model, val_iter, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2QulBjAWW6z",
        "outputId": "e748eaa8-7e3f-40c3-8db1-c34ddd020dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_f1 = evaluate(model, test_iter, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIvLzv7rYjsz",
        "outputId": "8adeecac-10dc-4ef0-df2b-5d628df7aa2e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on vaccines test set \n",
        "# (0.8434282392263412, 0.6831683168316832, 0.7058374249863612)\n",
        "# evaluation on masks test set\n",
        "# (1.070494016011556, 0.45555555555555555, 0.4294701675136458)\n",
        "test_loss, test_acc, test_f1"
      ],
      "metadata": {
        "id": "Tz0Bo4MlbkEw",
        "outputId": "49785474-c04f-4507-d1d9-fc204bcf8ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.070494016011556, 0.45555555555555555, 0.4294701675136458)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN + BiLSTM with weights\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        " \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "MAX_EPOCH = 15\n",
        "total_step = len(train_iter)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iter, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/CNN/CNN_LSTM_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlcLd5a4AoZh",
        "outputId": "630ff201-7406-4468-cad7-37deaba86fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:   7%|▋         | 1/15 [11:11<2:36:40, 671.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [1/15], Train Loss: 0.2706, Validation Loss: 0.9916, Validation Accuracy: 0.5591, Validation F1: 0.5499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  13%|█▎        | 2/15 [23:28<2:33:53, 710.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [2/15], Train Loss: 0.1426, Validation Loss: 1.4493, Validation Accuracy: 0.5388, Validation F1: 0.5145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  20%|██        | 3/15 [35:45<2:24:29, 722.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [3/15], Train Loss: 0.1180, Validation Loss: 1.6906, Validation Accuracy: 0.5523, Validation F1: 0.5129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  27%|██▋       | 4/15 [47:21<2:10:30, 711.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [4/15], Train Loss: 0.0640, Validation Loss: 2.3016, Validation Accuracy: 0.5222, Validation F1: 0.4995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  33%|███▎      | 5/15 [59:11<1:58:32, 711.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [5/15], Train Loss: 0.0300, Validation Loss: 2.2696, Validation Accuracy: 0.5391, Validation F1: 0.5232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  40%|████      | 6/15 [1:11:11<1:47:07, 714.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [6/15], Train Loss: 0.0228, Validation Loss: 2.3322, Validation Accuracy: 0.5415, Validation F1: 0.5168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  47%|████▋     | 7/15 [1:22:47<1:34:26, 708.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [7/15], Train Loss: 0.0179, Validation Loss: 2.3324, Validation Accuracy: 0.5477, Validation F1: 0.5388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  53%|█████▎    | 8/15 [1:35:41<1:25:03, 729.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [8/15], Train Loss: 0.0148, Validation Loss: 2.5006, Validation Accuracy: 0.5420, Validation F1: 0.5247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  60%|██████    | 9/15 [1:47:59<1:13:12, 732.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [9/15], Train Loss: 0.0136, Validation Loss: 2.6458, Validation Accuracy: 0.5262, Validation F1: 0.5203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  67%|██████▋   | 10/15 [2:00:16<1:01:07, 733.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [10/15], Train Loss: 0.0106, Validation Loss: 2.5830, Validation Accuracy: 0.5543, Validation F1: 0.5393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  73%|███████▎  | 11/15 [2:12:35<49:00, 735.20s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [11/15], Train Loss: 0.0086, Validation Loss: 2.6566, Validation Accuracy: 0.5423, Validation F1: 0.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  80%|████████  | 12/15 [2:24:45<36:41, 733.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [12/15], Train Loss: 0.0117, Validation Loss: 2.3755, Validation Accuracy: 0.5372, Validation F1: 0.5164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  87%|████████▋ | 13/15 [2:35:55<23:48, 714.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [13/15], Train Loss: 0.0365, Validation Loss: 2.0675, Validation Accuracy: 0.5340, Validation F1: 0.5133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  93%|█████████▎| 14/15 [2:44:38<10:56, 656.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [14/15], Train Loss: 0.0216, Validation Loss: 2.3923, Validation Accuracy: 0.5390, Validation F1: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch: 100%|██████████| 15/15 [2:53:31<00:00, 694.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [15/15], Train Loss: 0.0173, Validation Loss: 2.7553, Validation Accuracy: 0.5351, Validation F1: 0.5084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N1j3AdtdAgbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM-71Rt7oUMD"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "# the vocabulary size\n",
        "vocabulary_size = len(TEXT.vocab.stoi) \n",
        "\n",
        "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
        "embedding_dim = 200 \n",
        "\n",
        "# region size as 2, 3, and 4\n",
        "kernel_sizes = [2,3,4] \n",
        "\n",
        "# the number of kernel in each region size\n",
        "kernels_num = 32 \n",
        "\n",
        "# The dropout rate is set to be 0.5.\n",
        "dropout = 0.2\n",
        "\n",
        "# The output size of labels.\n",
        "output_size = 3\n",
        "\n",
        "# learning rate is set to be 0.01.\n",
        "lr = 0.001        \n",
        "\n",
        "# The number of iteration is set to be 5.\n",
        "num_epoch = 20  \n",
        "\n",
        "# employ class CNN_Text and assign to cnn\n",
        "model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HxfibzEo3dq"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        batch_input, labels = batch.tweet, batch.label\n",
        "        batch_input = batch_input.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_input)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.cpu().item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            batch_input, labels = batch.tweet, batch.label\n",
        "            batch_input = batch_input.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch_input)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muuUYl9Uo_ha",
        "outputId": "6118b8d4-89b0-4382-b361-707aff7114d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   7%|▋         | 1/15 [00:35<08:18, 35.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [1/15], Train Loss: 0.9379, Validation Loss: 0.9751, Validation Accuracy: 0.5516, Validation F1: 0.4065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 2/15 [01:07<07:14, 33.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [2/15], Train Loss: 0.8662, Validation Loss: 0.9735, Validation Accuracy: 0.5557, Validation F1: 0.4095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 3/15 [01:39<06:34, 32.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [3/15], Train Loss: 0.8116, Validation Loss: 0.9779, Validation Accuracy: 0.5514, Validation F1: 0.4051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 4/15 [02:11<05:58, 32.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [4/15], Train Loss: 0.7655, Validation Loss: 0.9819, Validation Accuracy: 0.5484, Validation F1: 0.4033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 5/15 [02:44<05:24, 32.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [5/15], Train Loss: 0.7219, Validation Loss: 0.9711, Validation Accuracy: 0.5601, Validation F1: 0.5142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 6/15 [03:16<04:51, 32.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [6/15], Train Loss: 0.6681, Validation Loss: 0.9745, Validation Accuracy: 0.5544, Validation F1: 0.5326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 7/15 [03:48<04:17, 32.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [7/15], Train Loss: 0.6277, Validation Loss: 0.9750, Validation Accuracy: 0.5550, Validation F1: 0.5265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 8/15 [04:20<03:44, 32.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [8/15], Train Loss: 0.6033, Validation Loss: 0.9738, Validation Accuracy: 0.5568, Validation F1: 0.5310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 9/15 [04:52<03:12, 32.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [9/15], Train Loss: 0.5890, Validation Loss: 0.9814, Validation Accuracy: 0.5482, Validation F1: 0.5321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 10/15 [05:24<02:40, 32.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [10/15], Train Loss: 0.5809, Validation Loss: 0.9819, Validation Accuracy: 0.5479, Validation F1: 0.5329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 11/15 [05:58<02:10, 32.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [11/15], Train Loss: 0.5755, Validation Loss: 0.9807, Validation Accuracy: 0.5514, Validation F1: 0.5345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 12/15 [06:31<01:38, 32.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [12/15], Train Loss: 0.5721, Validation Loss: 0.9813, Validation Accuracy: 0.5482, Validation F1: 0.5308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 13/15 [07:03<01:05, 32.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [13/15], Train Loss: 0.5697, Validation Loss: 0.9783, Validation Accuracy: 0.5539, Validation F1: 0.5352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  93%|█████████▎| 14/15 [07:35<00:32, 32.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [14/15], Train Loss: 0.5678, Validation Loss: 0.9794, Validation Accuracy: 0.5550, Validation F1: 0.5352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 15/15 [08:06<00:00, 32.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch [15/15], Train Loss: 0.5667, Validation Loss: 0.9921, Validation Accuracy: 0.5386, Validation F1: 0.5266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model CNN + BiLSLM\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        " \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "MAX_EPOCH = 15\n",
        "total_step = len(train_iter)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iter, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    # torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_cnn/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n",
        "\n",
        "# Epoch:   7%|▋         | 1/15 [01:03<14:48, 63.45s/it]\n",
        "#  Epoch [1/15], Train Loss: 0.9828, Validation Loss: 1.0399, Validation Accuracy: 0.5085, Validation F1: 0.3738\n",
        "# Epoch:  13%|█▎        | 2/15 [02:20<15:31, 71.66s/it]\n",
        "#  Epoch [2/15], Train Loss: 0.9366, Validation Loss: 1.0460, Validation Accuracy: 0.5041, Validation F1: 0.3671\n",
        "# Epoch:  20%|██        | 3/15 [03:44<15:25, 77.14s/it]\n",
        "#  Epoch [3/15], Train Loss: 0.9391, Validation Loss: 1.0554, Validation Accuracy: 0.4956, Validation F1: 0.3646\n",
        "# Epoch:  27%|██▋       | 4/15 [05:23<15:45, 85.93s/it]\n",
        "#  Epoch [4/15], Train Loss: 0.9640, Validation Loss: 1.0540, Validation Accuracy: 0.4968, Validation F1: 0.3647\n",
        "# Epoch:  33%|███▎      | 5/15 [07:09<15:29, 92.93s/it]\n",
        "#  Epoch [5/15], Train Loss: 0.9582, Validation Loss: 1.0523, Validation Accuracy: 0.4993, Validation F1: 0.3674\n",
        "# Epoch:  40%|████      | 6/15 [08:58<14:46, 98.51s/it]\n",
        "#  Epoch [6/15], Train Loss: 0.9642, Validation Loss: 1.0565, Validation Accuracy: 0.4948, Validation F1: 0.3642\n",
        "# Epoch:  47%|████▋     | 7/15 [10:46<13:32, 101.53s/it]\n",
        "#  Epoch [7/15], Train Loss: 0.9660, Validation Loss: 1.0878, Validation Accuracy: 0.4637, Validation F1: 0.3239\n",
        "# Epoch:  53%|█████▎    | 8/15 [12:35<12:07, 103.95s/it]\n",
        "#  Epoch [8/15], Train Loss: 0.9774, Validation Loss: 1.0638, Validation Accuracy: 0.4875, Validation F1: 0.3552\n",
        "# Epoch:  60%|██████    | 9/15 [14:25<10:35, 105.92s/it]\n",
        "#  Epoch [9/15], Train Loss: 0.9780, Validation Loss: 1.0766, Validation Accuracy: 0.4749, Validation F1: 0.3356\n",
        "# Epoch:  67%|██████▋   | 10/15 [16:15<08:54, 106.95s/it]\n",
        "#  Epoch [10/15], Train Loss: 0.9709, Validation Loss: 1.0659, Validation Accuracy: 0.4856, Validation F1: 0.3563\n",
        "# Epoch:  73%|███████▎  | 11/15 [18:04<07:10, 107.62s/it]\n",
        "#  Epoch [11/15], Train Loss: 0.9655, Validation Loss: 1.0607, Validation Accuracy: 0.4906, Validation F1: 0.3608\n",
        "# Epoch:  80%|████████  | 12/15 [19:52<05:23, 107.98s/it]\n",
        "#  Epoch [12/15], Train Loss: 0.9754, Validation Loss: 1.0661, Validation Accuracy: 0.4854, Validation F1: 0.3537\n",
        "# Epoch:  87%|████████▋ | 13/15 [21:41<03:36, 108.29s/it]\n",
        "#  Epoch [13/15], Train Loss: 0.9840, Validation Loss: 1.0735, Validation Accuracy: 0.4778, Validation F1: 0.3515\n",
        "# Epoch:  93%|█████████▎| 14/15 [23:32<01:48, 108.85s/it]\n",
        "#  Epoch [14/15], Train Loss: 0.9954, Validation Loss: 1.0833, Validation Accuracy: 0.4681, Validation F1: 0.3401\n",
        "# Epoch: 100%|██████████| 15/15 [25:23<00:00, 101.57s/it]\n",
        "#  Epoch [15/15], Train Loss: 0.9905, Validation Loss: 1.0833, Validation Accuracy: 0.4681, Validation F1: 0.3437  \n",
        "\n",
        "\n",
        "# No weights \n",
        "# kernel_sizes = [3,4,5] \n",
        "#  Epoch [8/15], Train Loss: 0.5756, Validation Loss: 0.9943, Validation Accuracy: 0.5319, Validation F1: 0.5041\n",
        "# kernel_sizes = [4,5,6] \n",
        "# Epoch [12/15], Train Loss: 0.5570, Validation Loss: 0.9870, Validation Accuracy: 0.5425, Validation F1: 0.5204\n",
        "# min_freq = 2\n",
        "#  Epoch [9/15], Train Loss: 0.5744, Validation Loss: 0.9910, Validation Accuracy: 0.5388, Validation F1: 0.5167\n",
        "# kernel_sizes = [2,3,4]\n",
        "# Epoch [7/15], Train Loss: 0.6414, Validation Loss: 0.9785, Validation Accuracy: 0.5548, Validation F1: 0.5266\n",
        "\n",
        "# CNN+BiLSTM\n",
        "# Epoch [5/15], Train Loss: 0.2907, Validation Loss: 1.7040, Validation Accuracy: 0.5383, Validation F1: 0.5128\n",
        "\n",
        "# with weights\n",
        "# CNN \n",
        "# Epoch [14/15], Train Loss: 0.5678, Validation Loss: 0.9794, Validation Accuracy: 0.5550, Validation F1: 0.5352"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O2_ClarKsPC"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, args):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.args = args\n",
        "        self.hidden_dim = args.lstm_hidden_dim\n",
        "        self.num_layers = args.lstm_num_layers\n",
        "        V = args.embed_num\n",
        "        D = args.embed_dim\n",
        "        C = args.class_num\n",
        "        # self.embed = nn.Embedding(V, D, max_norm=config.max_norm)\n",
        "        self.embed = nn.Embedding(V, D, padding_idx=args.paddingId)\n",
        "        # pretrained  embedding\n",
        "        if args.word_Embedding:\n",
        "            self.embed.weight.data.copy_(args.pretrained_weight)\n",
        "        self.bilstm = nn.LSTM(D, self.hidden_dim // 2, num_layers=1, dropout=args.dropout, bidirectional=True, bias=False)\n",
        "        print(self.bilstm)\n",
        "\n",
        "        self.hidden2label1 = nn.Linear(self.hidden_dim, self.hidden_dim // 2)\n",
        "        self.hidden2label2 = nn.Linear(self.hidden_dim // 2, C)\n",
        "        # self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embed(x)\n",
        "        x = embed.view(len(x), embed.size(1), -1)\n",
        "        bilstm_out, _ = self.bilstm(x)\n",
        "\n",
        "        bilstm_out = torch.transpose(bilstm_out, 0, 1)\n",
        "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
        "        bilstm_out = F.tanh(bilstm_out)\n",
        "        bilstm_out = F.max_pool1d(bilstm_out, bilstm_out.size(2)).squeeze(2)\n",
        "        y = self.hidden2label1(bilstm_out)\n",
        "        y = self.hidden2label2(y)\n",
        "        logit = y\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4BqQGWLLTog",
        "outputId": "39515dcc-6c7d-4f84-bfd4-918d595bd4ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM(300, 256, bias=False, dropout=0.2, bidirectional=True)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vocabulary_size = len(TEXT.vocab.stoi) \n",
        "hidden_dim = 512\n",
        "embedding_dim = 300 \n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# The output size of labels.\n",
        "output_size = 3\n",
        "\n",
        "# learning rate is set to be 0.01.\n",
        "lr = 0.001        \n",
        "\n",
        "# The number of iteration is set to be 5.\n",
        "num_epoch = 20 \n",
        "\n",
        "class BiLSTMrgs:\n",
        "  def __init__(self, hidden_dim, num_layers, vocabulary_size, embedding_dim, output_size, dropout) -> None:\n",
        "      self.lstm_hidden_dim = hidden_dim\n",
        "      self.lstm_num_layers = num_layers\n",
        "      self.embed_num = vocabulary_size \n",
        "      self.embed_dim = embedding_dim\n",
        "      self.class_num = output_size\n",
        "      self.dropout = dropout\n",
        "      self.paddingId = None\n",
        "      self.word_Embedding = None\n",
        "      self.cuda = True\n",
        "\n",
        "\n",
        "args_for_lstm = BiLSTMrgs(hidden_dim, num_layers, vocabulary_size, embedding_dim, output_size, dropout)\n",
        "model = BiLSTM(args_for_lstm).to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        " \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVOR6NGWMkpO",
        "outputId": "48bcc0f6-d92d-474a-dbe3-74e58d4d151a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:   7%|▋         | 1/15 [01:57<27:24, 117.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/15], Train Loss: 0.8965, Validation Loss: 0.9958, Validation Accuracy: 0.5100, Validation F1: 0.5047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  13%|█▎        | 2/15 [03:58<25:56, 119.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/15], Train Loss: 0.5663, Validation Loss: 1.0299, Validation Accuracy: 0.5500, Validation F1: 0.5221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  20%|██        | 3/15 [05:57<23:49, 119.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/15], Train Loss: 0.3105, Validation Loss: 1.4682, Validation Accuracy: 0.5028, Validation F1: 0.4975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  27%|██▋       | 4/15 [07:56<21:51, 119.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [4/15], Train Loss: 0.2165, Validation Loss: 1.8321, Validation Accuracy: 0.5107, Validation F1: 0.4996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  33%|███▎      | 5/15 [10:02<20:14, 121.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [5/15], Train Loss: 0.1512, Validation Loss: 1.9470, Validation Accuracy: 0.5456, Validation F1: 0.4959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  40%|████      | 6/15 [12:05<18:19, 122.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [6/15], Train Loss: 0.1758, Validation Loss: 1.7522, Validation Accuracy: 0.5423, Validation F1: 0.5167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  47%|████▋     | 7/15 [14:08<16:18, 122.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [7/15], Train Loss: 0.0770, Validation Loss: 2.0879, Validation Accuracy: 0.5335, Validation F1: 0.5170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  53%|█████▎    | 8/15 [16:11<14:18, 122.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [8/15], Train Loss: 0.0285, Validation Loss: 2.1142, Validation Accuracy: 0.5427, Validation F1: 0.5132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  60%|██████    | 9/15 [18:10<12:08, 121.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [9/15], Train Loss: 0.0188, Validation Loss: 2.1172, Validation Accuracy: 0.5457, Validation F1: 0.5174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  67%|██████▋   | 10/15 [20:03<09:54, 118.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [10/15], Train Loss: 0.0145, Validation Loss: 2.1538, Validation Accuracy: 0.5496, Validation F1: 0.5132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  73%|███████▎  | 11/15 [21:59<07:52, 118.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [11/15], Train Loss: 0.0117, Validation Loss: 2.1255, Validation Accuracy: 0.5489, Validation F1: 0.5212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  80%|████████  | 12/15 [23:56<05:53, 117.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [12/15], Train Loss: 0.0111, Validation Loss: 2.2756, Validation Accuracy: 0.5507, Validation F1: 0.5067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  87%|████████▋ | 13/15 [25:46<03:50, 115.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [13/15], Train Loss: 0.0118, Validation Loss: 2.1103, Validation Accuracy: 0.5447, Validation F1: 0.5181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch:  93%|█████████▎| 14/15 [27:38<01:54, 114.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [14/15], Train Loss: 0.0098, Validation Loss: 2.2797, Validation Accuracy: 0.5496, Validation F1: 0.5066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "Epoch: 100%|██████████| 15/15 [29:33<00:00, 118.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [15/15], Train Loss: 0.0102, Validation Loss: 2.1585, Validation Accuracy: 0.5452, Validation F1: 0.5228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model BiLSLM\n",
        "MAX_EPOCH = 15\n",
        "total_step = len(train_iter)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iter, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    # torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_cnn/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n",
        "# Epoch [15/15], Train Loss: 0.0102, Validation Loss: 2.1585, Validation Accuracy: 0.5452, Validation F1: 0.5228"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xolIxrAnoKk2"
      },
      "outputs": [],
      "source": [
        "class CNN_Text_emb(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
        "        '''\n",
        "        vocabulary_size: vocabulary size\n",
        "        embedding_dim: word embedding size\n",
        "        output_size: number of classes in prediction\n",
        "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
        "        region_sizes: height of kernels of convolutional layers\n",
        "        dropout: dropout rate\n",
        "        '''\n",
        "        super(CNN_Text_emb, self).__init__()\n",
        "        Ci = 1\n",
        "        self.embeddings = nn.Embedding.from_pretrained(pre_trained_emb)\n",
        "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
        "\n",
        "    def forward(self, x):        \n",
        "        input_embeddings = self.embeddings(x)  \n",
        "        input_embeddings = input_embeddings.permute(1,0,2)\n",
        "        input_embeddings = input_embeddings.unsqueeze(1)\n",
        "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
        "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
        "        concat_list = torch.cat(max_pooling_outputs, 1) \n",
        "        drop_output = self.dropout(concat_list) \n",
        "        fc1_output = self.fc(drop_output) \n",
        "        final_output = F.softmax(fc1_output,dim=1)\n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p8h7zORVLN0"
      },
      "outputs": [],
      "source": [
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
        "        '''\n",
        "        vocabulary_size: vocabulary size\n",
        "        embedding_dim: word embedding size\n",
        "        output_size: number of classes in prediction\n",
        "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
        "        region_sizes: height of kernels of convolutional layers\n",
        "        dropout: dropout rate\n",
        "        '''\n",
        "        super(CNN_Text, self).__init__()\n",
        "        # the size of input channel is 1.\n",
        "        Ci = 1\n",
        "        \n",
        "        # word embedding layer\n",
        "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim )\n",
        "        \n",
        "        # convolution with kernels\n",
        "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
        "        \n",
        "        # a dropout layer\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        \n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input x  [sequence length, batch size]\n",
        "        \n",
        "        input_embeddings = self.embeddings(x)  \n",
        "        # (batch size, word_sequence, embedding_dim) word embedding\n",
        "\n",
        "        input_embeddings = input_embeddings.permute(1,0,2)\n",
        "        input_embeddings = input_embeddings.unsqueeze(1)\n",
        "        #  [batch size, number of channel is one, sequence length, embeeding size]\n",
        "\n",
        "        # convolutional layers\n",
        "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
        "        \n",
        "        # to get the maximum value of filtered tensor\n",
        "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
        "        \n",
        "        concat_list = torch.cat(max_pooling_outputs, 1) # concatenate representations\n",
        "        \n",
        "        drop_output = self.dropout(concat_list)  # add drop layer\n",
        "        \n",
        "        fc1_output = self.fc(drop_output)  # get the fc1 using a fully connected layer\n",
        "        \n",
        "        final_output = F.softmax(fc1_output,dim=1)\n",
        "        \n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCi2QikIVZp0"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "# the vocabulary size\n",
        "vocabulary_size = len(TEXT.vocab.stoi) \n",
        "\n",
        "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
        "embedding_dim = 400 \n",
        "\n",
        "# region size as 2, 3, and 4\n",
        "kernel_sizes = [3,2,1] \n",
        "\n",
        "# the number of kernel in each region size\n",
        "kernels_num = 32 \n",
        "\n",
        "# The dropout rate is set to be 0.5.\n",
        "dropout = 0.2\n",
        "\n",
        "# The output size of labels.\n",
        "output_size = 3\n",
        "\n",
        "# learning rate is set to be 0.01.\n",
        "lr = 0.001        \n",
        "\n",
        "# The number of iteration is set to be 5.\n",
        "num_epoch = 20  \n",
        "\n",
        "# employ class CNN_Text and assign to cnn\n",
        "model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrFo7jWXVmEP",
        "outputId": "6c6d0483-f41f-4d0e-d014-d43c7ad17208"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 1/20 [01:32<29:20, 92.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/20], Train Loss: 0.9758, Validation Loss: 0.9931, Validation Accuracy: 0.5254, Validation F1: 0.3860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 2/20 [03:01<27:05, 90.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/20], Train Loss: 0.8735, Validation Loss: 0.9853, Validation Accuracy: 0.5434, Validation F1: 0.4003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  15%|█▌        | 3/20 [04:28<25:13, 89.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/20], Train Loss: 0.8083, Validation Loss: 0.9884, Validation Accuracy: 0.5404, Validation F1: 0.3981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 4/20 [05:58<23:50, 89.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [4/20], Train Loss: 0.7655, Validation Loss: 0.9917, Validation Accuracy: 0.5363, Validation F1: 0.3949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 5/20 [07:27<22:19, 89.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [5/20], Train Loss: 0.7425, Validation Loss: 0.9945, Validation Accuracy: 0.5356, Validation F1: 0.3947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 6/20 [08:56<20:44, 88.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [6/20], Train Loss: 0.7282, Validation Loss: 0.9970, Validation Accuracy: 0.5324, Validation F1: 0.3920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  35%|███▌      | 7/20 [10:24<19:12, 88.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [7/20], Train Loss: 0.7037, Validation Loss: 0.9860, Validation Accuracy: 0.5440, Validation F1: 0.4835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 8/20 [11:53<17:46, 88.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [8/20], Train Loss: 0.6542, Validation Loss: 0.9860, Validation Accuracy: 0.5456, Validation F1: 0.5226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  45%|████▌     | 9/20 [13:21<16:13, 88.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [9/20], Train Loss: 0.6195, Validation Loss: 0.9852, Validation Accuracy: 0.5488, Validation F1: 0.5250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 10/20 [14:50<14:46, 88.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [10/20], Train Loss: 0.5982, Validation Loss: 0.9834, Validation Accuracy: 0.5484, Validation F1: 0.5281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  55%|█████▌    | 11/20 [16:19<13:19, 88.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [11/20], Train Loss: 0.5884, Validation Loss: 0.9844, Validation Accuracy: 0.5461, Validation F1: 0.5216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 12/20 [17:45<11:44, 88.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [12/20], Train Loss: 0.5819, Validation Loss: 0.9844, Validation Accuracy: 0.5447, Validation F1: 0.5204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  65%|██████▌   | 13/20 [19:13<10:16, 88.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [13/20], Train Loss: 0.5769, Validation Loss: 0.9880, Validation Accuracy: 0.5416, Validation F1: 0.5152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 14/20 [20:40<08:46, 87.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [14/20], Train Loss: 0.5741, Validation Loss: 0.9866, Validation Accuracy: 0.5441, Validation F1: 0.5164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 15/20 [22:08<07:18, 87.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [15/20], Train Loss: 0.5723, Validation Loss: 0.9895, Validation Accuracy: 0.5429, Validation F1: 0.5110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 16/20 [23:36<05:51, 87.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [16/20], Train Loss: 0.5709, Validation Loss: 0.9921, Validation Accuracy: 0.5390, Validation F1: 0.5141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  85%|████████▌ | 17/20 [25:03<04:22, 87.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [17/20], Train Loss: 0.5690, Validation Loss: 0.9920, Validation Accuracy: 0.5411, Validation F1: 0.5147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 18/20 [26:30<02:54, 87.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [18/20], Train Loss: 0.5685, Validation Loss: 0.9924, Validation Accuracy: 0.5404, Validation F1: 0.5105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  95%|█████████▌| 19/20 [27:57<01:27, 87.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [19/20], Train Loss: 0.5675, Validation Loss: 0.9932, Validation Accuracy: 0.5415, Validation F1: 0.5197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 20/20 [29:23<00:00, 88.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [20/20], Train Loss: 0.5671, Validation Loss: 0.9929, Validation Accuracy: 0.5383, Validation F1: 0.5064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model DEEP CNN\n",
        "MAX_EPOCH = 20\n",
        "total_step = len(train_iter)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "import torch.optim as optim\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iter, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    # torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_cnn/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IER-RedNUukq"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "import random\n",
        "import torch.optim as optim\n",
        "LEARNING_RATE=.1\n",
        "MAX_EPOCH=20\n",
        "\n",
        "\n",
        "def random_search(num_iter):\n",
        "    results = []\n",
        "    for i in range(num_iter):\n",
        "        config = {\n",
        "            #define hyperparameters here\n",
        "            \"kernel_sizes\": random.choice([[1,2,3],[2,3,4],[3,4,5],[4,5,6],[1,4,6],[1,3,6],[2,5,4]]),\n",
        "            \"embedding_dim\": random.choice([300, 400, 500, 600, 700, 800]),\n",
        "            \"dropout\" : random.choice([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]),\n",
        "            \"lr\": random.choice([0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
        "\n",
        "            \n",
        "        }\n",
        "        \n",
        "        print(\"new config\")\n",
        "        print(config)\n",
        "        model = CNN_Text(vocabulary_size=len(TEXT.vocab.stoi), embedding_dim=config[\"embedding_dim\"], output_size=3, kernel_num=32, region_sizes=config[\"kernel_sizes\"],  dropout=config[\"dropout\"]).to(device)\n",
        "        # model = ConvNet_1(layer_num=config[\"layers\"],filtersize=config[\"kernel_size\"],filters=config[\"n_filters\"],\n",
        "        #                 nonlin=config[\"activation\"], output_size=5, VOCAB_SIZE=VOCAB_SIZE, WORD_VEC_SIZE=config[\"WORD_VEC_SIZE\"],\n",
        "        #                 num_layers=config[\"num_layers\"], dropout=config[\"dropout\"])\n",
        "\n",
        "    #     class CNN_Text(nn.Module):\n",
        "    # def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
        "    #     '''\n",
        "\n",
        "        import torch.optim as optim\n",
        "        def init_weights(m):\n",
        "            for name, param in m.named_parameters():\n",
        "                if 'weight' in name:\n",
        "                    nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "                else:\n",
        "                    nn.init.constant_(param.data, 0)\n",
        "            \n",
        "        model.apply(init_weights)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])   # define a optimizer for backpropagation\n",
        "        loss_func = nn.CrossEntropyLoss()\n",
        "        model.to(device)\n",
        " \n",
        "    \n",
        "        max_val = 0\n",
        "        best_epoch = 0\n",
        "        for epoch in range(20):\n",
        "        # train the model for one pass over the data\n",
        "            train_loss = train(model, train_iter, optimizer, criterion) \n",
        "        # compute the training accuracy\n",
        "        # compute the validation accuracy\n",
        "            val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "            print(val_acc)\n",
        "            if val_acc > max_val:\n",
        "                max_val = val_acc\n",
        "                best_epoch = epoch+1\n",
        "        # print the loss for every epoch\n",
        "            print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n",
        "        results.append((max_val,best_epoch,config))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSSIck7vbkpv",
        "outputId": "c4d8c466-dccd-47f3-a06e-5cac484747b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new config\n",
            "{'kernel_sizes': [2, 5, 4], 'embedding_dim': 600, 'dropout': 0.7, 'lr': 1e-05}\n",
            "0.4266903914590747\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.1106, Validation Loss: 1.0838, Validation Accuracy: 0.4267, Validation F1: 0.1994\n",
            "0.4266903914590747\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.1051, Validation Loss: 1.0791, Validation Accuracy: 0.4267, Validation F1: 0.1994\n",
            "0.4266903914590747\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0927, Validation Loss: 1.0743, Validation Accuracy: 0.4267, Validation F1: 0.1994\n",
            "0.4268683274021352\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0886, Validation Loss: 1.0694, Validation Accuracy: 0.4269, Validation F1: 0.1997\n",
            "0.42758007117437724\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.0845, Validation Loss: 1.0641, Validation Accuracy: 0.4276, Validation F1: 0.2011\n",
            "0.4295373665480427\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0803, Validation Loss: 1.0596, Validation Accuracy: 0.4295, Validation F1: 0.2055\n",
            "0.4318505338078292\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0710, Validation Loss: 1.0548, Validation Accuracy: 0.4319, Validation F1: 0.2133\n",
            "0.43683274021352314\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0670, Validation Loss: 1.0506, Validation Accuracy: 0.4368, Validation F1: 0.2273\n",
            "0.4396797153024911\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0619, Validation Loss: 1.0469, Validation Accuracy: 0.4397, Validation F1: 0.2443\n",
            "0.44661921708185054\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0603, Validation Loss: 1.0440, Validation Accuracy: 0.4466, Validation F1: 0.2681\n",
            "0.4523131672597865\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0568, Validation Loss: 1.0414, Validation Accuracy: 0.4523, Validation F1: 0.2901\n",
            "0.45960854092526693\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0532, Validation Loss: 1.0395, Validation Accuracy: 0.4596, Validation F1: 0.3071\n",
            "0.4695729537366548\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0526, Validation Loss: 1.0378, Validation Accuracy: 0.4696, Validation F1: 0.3251\n",
            "0.47651245551601423\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.0473, Validation Loss: 1.0363, Validation Accuracy: 0.4765, Validation F1: 0.3384\n",
            "0.48078291814946617\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.0415, Validation Loss: 1.0350, Validation Accuracy: 0.4808, Validation F1: 0.3461\n",
            "0.4830960854092527\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.0404, Validation Loss: 1.0339, Validation Accuracy: 0.4831, Validation F1: 0.3518\n",
            "0.48825622775800714\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.0337, Validation Loss: 1.0330, Validation Accuracy: 0.4883, Validation F1: 0.3576\n",
            "0.4875444839857651\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.0334, Validation Loss: 1.0320, Validation Accuracy: 0.4875, Validation F1: 0.3575\n",
            "0.4886120996441281\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.0294, Validation Loss: 1.0309, Validation Accuracy: 0.4886, Validation F1: 0.3586\n",
            "0.48825622775800714\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.0296, Validation Loss: 1.0301, Validation Accuracy: 0.4883, Validation F1: 0.3588\n",
            "new config\n",
            "{'kernel_sizes': [2, 5, 4], 'embedding_dim': 600, 'dropout': 0.6, 'lr': 1e-05}\n",
            "0.3925266903914591\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.1082, Validation Loss: 1.0776, Validation Accuracy: 0.3925, Validation F1: 0.2408\n",
            "0.3998220640569395\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0954, Validation Loss: 1.0693, Validation Accuracy: 0.3998, Validation F1: 0.2551\n",
            "0.40373665480427046\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0825, Validation Loss: 1.0638, Validation Accuracy: 0.4037, Validation F1: 0.2663\n",
            "0.4099644128113879\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0741, Validation Loss: 1.0596, Validation Accuracy: 0.4100, Validation F1: 0.2787\n",
            "0.4190391459074733\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.0665, Validation Loss: 1.0562, Validation Accuracy: 0.4190, Validation F1: 0.2922\n",
            "0.4307829181494662\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0592, Validation Loss: 1.0533, Validation Accuracy: 0.4308, Validation F1: 0.3070\n",
            "0.44341637010676155\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0564, Validation Loss: 1.0506, Validation Accuracy: 0.4434, Validation F1: 0.3205\n",
            "0.45409252669039146\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0505, Validation Loss: 1.0481, Validation Accuracy: 0.4541, Validation F1: 0.3316\n",
            "0.46387900355871886\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0481, Validation Loss: 1.0460, Validation Accuracy: 0.4639, Validation F1: 0.3402\n",
            "0.46779359430604983\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0415, Validation Loss: 1.0439, Validation Accuracy: 0.4678, Validation F1: 0.3438\n",
            "0.47206405693950176\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0381, Validation Loss: 1.0421, Validation Accuracy: 0.4721, Validation F1: 0.3470\n",
            "0.4766903914590747\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0380, Validation Loss: 1.0404, Validation Accuracy: 0.4767, Validation F1: 0.3508\n",
            "0.4802491103202847\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0326, Validation Loss: 1.0388, Validation Accuracy: 0.4802, Validation F1: 0.3535\n",
            "0.4830960854092527\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.0323, Validation Loss: 1.0373, Validation Accuracy: 0.4831, Validation F1: 0.3555\n",
            "0.48683274021352313\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.0270, Validation Loss: 1.0359, Validation Accuracy: 0.4868, Validation F1: 0.3583\n",
            "0.4909252669039146\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.0243, Validation Loss: 1.0345, Validation Accuracy: 0.4909, Validation F1: 0.3613\n",
            "0.4930604982206406\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.0210, Validation Loss: 1.0331, Validation Accuracy: 0.4931, Validation F1: 0.3629\n",
            "0.49697508896797155\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.0170, Validation Loss: 1.0318, Validation Accuracy: 0.4970, Validation F1: 0.3658\n",
            "0.4987544483985765\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.0198, Validation Loss: 1.0305, Validation Accuracy: 0.4988, Validation F1: 0.3671\n",
            "0.5001779359430605\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.0140, Validation Loss: 1.0293, Validation Accuracy: 0.5002, Validation F1: 0.3682\n",
            "new config\n",
            "{'kernel_sizes': [3, 4, 5], 'embedding_dim': 300, 'dropout': 0.1, 'lr': 1e-05}\n",
            "0.3774021352313167\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.1121, Validation Loss: 1.0941, Validation Accuracy: 0.3774, Validation F1: 0.3536\n",
            "0.43612099644128116\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0860, Validation Loss: 1.0783, Validation Accuracy: 0.4361, Validation F1: 0.3288\n",
            "0.44661921708185054\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0680, Validation Loss: 1.0681, Validation Accuracy: 0.4466, Validation F1: 0.3289\n",
            "0.451779359430605\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0557, Validation Loss: 1.0611, Validation Accuracy: 0.4518, Validation F1: 0.3326\n",
            "0.4603202846975089\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.0459, Validation Loss: 1.0560, Validation Accuracy: 0.4603, Validation F1: 0.3388\n",
            "0.46601423487544485\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0367, Validation Loss: 1.0520, Validation Accuracy: 0.4660, Validation F1: 0.3430\n",
            "0.46708185053380785\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0317, Validation Loss: 1.0487, Validation Accuracy: 0.4671, Validation F1: 0.3438\n",
            "0.47046263345195727\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0252, Validation Loss: 1.0460, Validation Accuracy: 0.4705, Validation F1: 0.3463\n",
            "0.47597864768683273\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0193, Validation Loss: 1.0435, Validation Accuracy: 0.4760, Validation F1: 0.3504\n",
            "0.4790035587188612\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0152, Validation Loss: 1.0414, Validation Accuracy: 0.4790, Validation F1: 0.3527\n",
            "0.48131672597864766\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0107, Validation Loss: 1.0394, Validation Accuracy: 0.4813, Validation F1: 0.3544\n",
            "0.48487544483985767\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0056, Validation Loss: 1.0376, Validation Accuracy: 0.4849, Validation F1: 0.3570\n",
            "0.48576512455516013\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0011, Validation Loss: 1.0359, Validation Accuracy: 0.4858, Validation F1: 0.3576\n",
            "0.4879003558718861\n",
            "\n",
            " Epoch [14/20], Train Loss: 0.9979, Validation Loss: 1.0344, Validation Accuracy: 0.4879, Validation F1: 0.3592\n",
            "0.4905693950177936\n",
            "\n",
            " Epoch [15/20], Train Loss: 0.9939, Validation Loss: 1.0329, Validation Accuracy: 0.4906, Validation F1: 0.3612\n",
            "0.49110320284697506\n",
            "\n",
            " Epoch [16/20], Train Loss: 0.9915, Validation Loss: 1.0315, Validation Accuracy: 0.4911, Validation F1: 0.3615\n",
            "0.4934163701067616\n",
            "\n",
            " Epoch [17/20], Train Loss: 0.9881, Validation Loss: 1.0303, Validation Accuracy: 0.4934, Validation F1: 0.3632\n",
            "0.49590747330960855\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.9842, Validation Loss: 1.0290, Validation Accuracy: 0.4959, Validation F1: 0.3650\n",
            "0.49608540925266903\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.9820, Validation Loss: 1.0279, Validation Accuracy: 0.4961, Validation F1: 0.3652\n",
            "0.49750889679715304\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.9779, Validation Loss: 1.0268, Validation Accuracy: 0.4975, Validation F1: 0.3662\n",
            "new config\n",
            "{'kernel_sizes': [2, 3, 4], 'embedding_dim': 600, 'dropout': 0.3, 'lr': 0.0001}\n",
            "0.4745551601423488\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0758, Validation Loss: 1.0394, Validation Accuracy: 0.4746, Validation F1: 0.3412\n",
            "0.4991103202846975\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0017, Validation Loss: 1.0226, Validation Accuracy: 0.4991, Validation F1: 0.3667\n",
            "0.5133451957295374\n",
            "\n",
            " Epoch [3/20], Train Loss: 0.9636, Validation Loss: 1.0128, Validation Accuracy: 0.5133, Validation F1: 0.3779\n",
            "0.5211743772241992\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.9396, Validation Loss: 1.0071, Validation Accuracy: 0.5212, Validation F1: 0.3836\n",
            "0.5229537366548043\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9166, Validation Loss: 1.0030, Validation Accuracy: 0.5230, Validation F1: 0.3845\n",
            "0.5259786476868328\n",
            "\n",
            " Epoch [6/20], Train Loss: 0.8967, Validation Loss: 0.9998, Validation Accuracy: 0.5260, Validation F1: 0.3866\n",
            "0.5304270462633452\n",
            "\n",
            " Epoch [7/20], Train Loss: 0.8789, Validation Loss: 0.9973, Validation Accuracy: 0.5304, Validation F1: 0.3899\n",
            "0.5304270462633452\n",
            "\n",
            " Epoch [8/20], Train Loss: 0.8629, Validation Loss: 0.9959, Validation Accuracy: 0.5304, Validation F1: 0.3895\n",
            "0.5320284697508897\n",
            "\n",
            " Epoch [9/20], Train Loss: 0.8471, Validation Loss: 0.9932, Validation Accuracy: 0.5320, Validation F1: 0.3912\n",
            "0.5322064056939502\n",
            "\n",
            " Epoch [10/20], Train Loss: 0.8341, Validation Loss: 0.9929, Validation Accuracy: 0.5322, Validation F1: 0.3910\n",
            "0.5332740213523132\n",
            "\n",
            " Epoch [11/20], Train Loss: 0.8214, Validation Loss: 0.9911, Validation Accuracy: 0.5333, Validation F1: 0.3921\n",
            "0.5350533807829182\n",
            "\n",
            " Epoch [12/20], Train Loss: 0.8102, Validation Loss: 0.9912, Validation Accuracy: 0.5351, Validation F1: 0.3935\n",
            "0.5336298932384341\n",
            "\n",
            " Epoch [13/20], Train Loss: 0.7979, Validation Loss: 0.9909, Validation Accuracy: 0.5336, Validation F1: 0.3923\n",
            "0.5350533807829182\n",
            "\n",
            " Epoch [14/20], Train Loss: 0.7870, Validation Loss: 0.9902, Validation Accuracy: 0.5351, Validation F1: 0.3936\n",
            "0.5357651245551601\n",
            "\n",
            " Epoch [15/20], Train Loss: 0.7787, Validation Loss: 0.9903, Validation Accuracy: 0.5358, Validation F1: 0.3940\n",
            "0.5361209964412811\n",
            "\n",
            " Epoch [16/20], Train Loss: 0.7706, Validation Loss: 0.9891, Validation Accuracy: 0.5361, Validation F1: 0.3947\n",
            "0.5371886120996441\n",
            "\n",
            " Epoch [17/20], Train Loss: 0.7590, Validation Loss: 0.9881, Validation Accuracy: 0.5372, Validation F1: 0.3966\n",
            "0.5377224199288256\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.7495, Validation Loss: 0.9876, Validation Accuracy: 0.5377, Validation F1: 0.3997\n",
            "0.5373665480427047\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.7371, Validation Loss: 0.9854, Validation Accuracy: 0.5374, Validation F1: 0.4114\n",
            "0.5419928825622776\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.7241, Validation Loss: 0.9841, Validation Accuracy: 0.5420, Validation F1: 0.4285\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 800, 'dropout': 0.6, 'lr': 0.01}\n",
            "0.49217081850533806\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0232, Validation Loss: 1.0591, Validation Accuracy: 0.4922, Validation F1: 0.3534\n",
            "0.45320284697508895\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0004, Validation Loss: 1.0980, Validation Accuracy: 0.4532, Validation F1: 0.3001\n",
            "0.44608540925266904\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0159, Validation Loss: 1.1054, Validation Accuracy: 0.4461, Validation F1: 0.2897\n",
            "0.5019572953736655\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0088, Validation Loss: 1.0490, Validation Accuracy: 0.5020, Validation F1: 0.3686\n",
            "0.4204626334519573\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.0259, Validation Loss: 1.1310, Validation Accuracy: 0.4205, Validation F1: 0.2507\n",
            "0.499288256227758\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0184, Validation Loss: 1.0522, Validation Accuracy: 0.4993, Validation F1: 0.3652\n",
            "0.4994661921708185\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0117, Validation Loss: 1.0521, Validation Accuracy: 0.4995, Validation F1: 0.3656\n",
            "0.501067615658363\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0042, Validation Loss: 1.0503, Validation Accuracy: 0.5011, Validation F1: 0.3660\n",
            "0.47366548042704626\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0058, Validation Loss: 1.0779, Validation Accuracy: 0.4737, Validation F1: 0.3324\n",
            "0.46761565836298935\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0654, Validation Loss: 1.0839, Validation Accuracy: 0.4676, Validation F1: 0.3229\n",
            "0.44928825622775803\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0343, Validation Loss: 1.1023, Validation Accuracy: 0.4493, Validation F1: 0.2974\n",
            "0.4592526690391459\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0364, Validation Loss: 1.0922, Validation Accuracy: 0.4593, Validation F1: 0.3127\n",
            "0.4291814946619217\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0939, Validation Loss: 1.1222, Validation Accuracy: 0.4292, Validation F1: 0.2089\n",
            "0.42811387900355874\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.1054, Validation Loss: 1.1233, Validation Accuracy: 0.4281, Validation F1: 0.2065\n",
            "0.4282918149466192\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.1019, Validation Loss: 1.1231, Validation Accuracy: 0.4283, Validation F1: 0.2067\n",
            "0.42704626334519574\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.1084, Validation Loss: 1.1244, Validation Accuracy: 0.4270, Validation F1: 0.2003\n",
            "0.42758007117437724\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.1090, Validation Loss: 1.1238, Validation Accuracy: 0.4276, Validation F1: 0.2041\n",
            "0.4430604982206406\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.1031, Validation Loss: 1.1084, Validation Accuracy: 0.4431, Validation F1: 0.2545\n",
            "0.4615658362989324\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.0699, Validation Loss: 1.0897, Validation Accuracy: 0.4616, Validation F1: 0.3280\n",
            "0.4588967971530249\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.0460, Validation Loss: 1.0927, Validation Accuracy: 0.4589, Validation F1: 0.3256\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 400, 'dropout': 0.4, 'lr': 1e-05}\n",
            "0.3909252669039146\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0961, Validation Loss: 1.0845, Validation Accuracy: 0.3909, Validation F1: 0.2221\n",
            "0.3953736654804271\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0805, Validation Loss: 1.0752, Validation Accuracy: 0.3954, Validation F1: 0.2311\n",
            "0.4078291814946619\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0680, Validation Loss: 1.0680, Validation Accuracy: 0.4078, Validation F1: 0.2567\n",
            "0.41583629893238433\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0595, Validation Loss: 1.0623, Validation Accuracy: 0.4158, Validation F1: 0.2789\n",
            "0.42366548042704627\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.0488, Validation Loss: 1.0578, Validation Accuracy: 0.4237, Validation F1: 0.2973\n",
            "0.4386120996441281\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0473, Validation Loss: 1.0540, Validation Accuracy: 0.4386, Validation F1: 0.3164\n",
            "0.45409252669039146\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0394, Validation Loss: 1.0510, Validation Accuracy: 0.4541, Validation F1: 0.3320\n",
            "0.4610320284697509\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0309, Validation Loss: 1.0483, Validation Accuracy: 0.4610, Validation F1: 0.3387\n",
            "0.4686832740213523\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0290, Validation Loss: 1.0461, Validation Accuracy: 0.4687, Validation F1: 0.3449\n",
            "0.4722419928825623\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0263, Validation Loss: 1.0441, Validation Accuracy: 0.4722, Validation F1: 0.3476\n",
            "0.47633451957295375\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0199, Validation Loss: 1.0422, Validation Accuracy: 0.4763, Validation F1: 0.3504\n",
            "0.4790035587188612\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0165, Validation Loss: 1.0406, Validation Accuracy: 0.4790, Validation F1: 0.3523\n",
            "0.48505338078291815\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0136, Validation Loss: 1.0390, Validation Accuracy: 0.4851, Validation F1: 0.3566\n",
            "0.48665480427046265\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.0099, Validation Loss: 1.0374, Validation Accuracy: 0.4867, Validation F1: 0.3576\n",
            "0.4896797153024911\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.0060, Validation Loss: 1.0360, Validation Accuracy: 0.4897, Validation F1: 0.3597\n",
            "0.4900355871886121\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.0014, Validation Loss: 1.0348, Validation Accuracy: 0.4900, Validation F1: 0.3601\n",
            "0.4918149466192171\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.0010, Validation Loss: 1.0335, Validation Accuracy: 0.4918, Validation F1: 0.3614\n",
            "0.49395017793594304\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.9997, Validation Loss: 1.0323, Validation Accuracy: 0.4940, Validation F1: 0.3629\n",
            "0.4923487544483986\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.9957, Validation Loss: 1.0311, Validation Accuracy: 0.4923, Validation F1: 0.3619\n",
            "0.4935943060498221\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.9945, Validation Loss: 1.0299, Validation Accuracy: 0.4936, Validation F1: 0.3628\n",
            "new config\n",
            "{'kernel_sizes': [1, 2, 3], 'embedding_dim': 800, 'dropout': 0.2, 'lr': 0.01}\n",
            "0.4923487544483986\n",
            "\n",
            " Epoch [1/20], Train Loss: 0.9844, Validation Loss: 1.0580, Validation Accuracy: 0.4923, Validation F1: 0.3551\n",
            "0.4284697508896797\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0036, Validation Loss: 1.1228, Validation Accuracy: 0.4285, Validation F1: 0.2045\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0765, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "new config\n",
            "{'kernel_sizes': [4, 5, 6], 'embedding_dim': 800, 'dropout': 0.4, 'lr': 0.01}\n",
            "0.4658362989323843\n",
            "\n",
            " Epoch [1/20], Train Loss: 0.9963, Validation Loss: 1.0850, Validation Accuracy: 0.4658, Validation F1: 0.2974\n",
            "0.5023131672597865\n",
            "\n",
            " Epoch [2/20], Train Loss: 0.9842, Validation Loss: 1.0489, Validation Accuracy: 0.5023, Validation F1: 0.3692\n",
            "0.4912811387900356\n",
            "\n",
            " Epoch [3/20], Train Loss: 0.9790, Validation Loss: 1.0604, Validation Accuracy: 0.4913, Validation F1: 0.3539\n",
            "0.49519572953736657\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.9860, Validation Loss: 1.0564, Validation Accuracy: 0.4952, Validation F1: 0.3644\n",
            "0.49608540925266903\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9899, Validation Loss: 1.0554, Validation Accuracy: 0.4961, Validation F1: 0.3620\n",
            "0.43416370106761565\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0097, Validation Loss: 1.1172, Validation Accuracy: 0.4342, Validation F1: 0.2218\n",
            "0.4332740213523132\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0843, Validation Loss: 1.1182, Validation Accuracy: 0.4333, Validation F1: 0.2230\n",
            "0.4697508896797153\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0517, Validation Loss: 1.0816, Validation Accuracy: 0.4698, Validation F1: 0.3154\n",
            "0.4745551601423488\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0081, Validation Loss: 1.0771, Validation Accuracy: 0.4746, Validation F1: 0.3434\n",
            "0.48612099644128115\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0210, Validation Loss: 1.0653, Validation Accuracy: 0.4861, Validation F1: 0.3445\n",
            "0.4987544483985765\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0303, Validation Loss: 1.0527, Validation Accuracy: 0.4988, Validation F1: 0.3622\n",
            "0.44270462633451957\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0238, Validation Loss: 1.1089, Validation Accuracy: 0.4427, Validation F1: 0.2883\n",
            "0.4400355871886121\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0248, Validation Loss: 1.1114, Validation Accuracy: 0.4400, Validation F1: 0.2575\n",
            "0.44341637010676155\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.0841, Validation Loss: 1.1080, Validation Accuracy: 0.4434, Validation F1: 0.2699\n",
            "0.44377224199288257\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.0758, Validation Loss: 1.1076, Validation Accuracy: 0.4438, Validation F1: 0.2707\n",
            "0.4322064056939502\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.1033, Validation Loss: 1.1192, Validation Accuracy: 0.4322, Validation F1: 0.2240\n",
            "0.48238434163701066\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.0549, Validation Loss: 1.0688, Validation Accuracy: 0.4824, Validation F1: 0.3490\n",
            "0.4364768683274021\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.0548, Validation Loss: 1.1149, Validation Accuracy: 0.4365, Validation F1: 0.2426\n",
            "0.43202846975088965\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.0872, Validation Loss: 1.1194, Validation Accuracy: 0.4320, Validation F1: 0.2190\n",
            "0.4309608540925267\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.1108, Validation Loss: 1.1204, Validation Accuracy: 0.4310, Validation F1: 0.2140\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 400, 'dropout': 0.2, 'lr': 0.001}\n",
            "0.5323843416370106\n",
            "\n",
            " Epoch [1/20], Train Loss: 0.9777, Validation Loss: 0.9917, Validation Accuracy: 0.5324, Validation F1: 0.3917\n",
            "0.5348754448398576\n",
            "\n",
            " Epoch [2/20], Train Loss: 0.8557, Validation Loss: 0.9855, Validation Accuracy: 0.5349, Validation F1: 0.3940\n",
            "0.5395017793594306\n",
            "\n",
            " Epoch [3/20], Train Loss: 0.7801, Validation Loss: 0.9863, Validation Accuracy: 0.5395, Validation F1: 0.3975\n",
            "0.5416370106761565\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.7319, Validation Loss: 0.9813, Validation Accuracy: 0.5416, Validation F1: 0.4622\n",
            "0.5544483985765124\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.6733, Validation Loss: 0.9747, Validation Accuracy: 0.5544, Validation F1: 0.5160\n",
            "0.5483985765124555\n",
            "\n",
            " Epoch [6/20], Train Loss: 0.6221, Validation Loss: 0.9769, Validation Accuracy: 0.5484, Validation F1: 0.5227\n",
            "0.5469750889679715\n",
            "\n",
            " Epoch [7/20], Train Loss: 0.5932, Validation Loss: 0.9772, Validation Accuracy: 0.5470, Validation F1: 0.5202\n",
            "0.546085409252669\n",
            "\n",
            " Epoch [8/20], Train Loss: 0.5801, Validation Loss: 0.9793, Validation Accuracy: 0.5461, Validation F1: 0.5191\n",
            "0.5501779359430605\n",
            "\n",
            " Epoch [9/20], Train Loss: 0.5726, Validation Loss: 0.9755, Validation Accuracy: 0.5502, Validation F1: 0.5217\n",
            "0.551067615658363\n",
            "\n",
            " Epoch [10/20], Train Loss: 0.5691, Validation Loss: 0.9770, Validation Accuracy: 0.5511, Validation F1: 0.5194\n",
            "0.5476868327402136\n",
            "\n",
            " Epoch [11/20], Train Loss: 0.5659, Validation Loss: 0.9789, Validation Accuracy: 0.5477, Validation F1: 0.5213\n",
            "0.5532028469750889\n",
            "\n",
            " Epoch [12/20], Train Loss: 0.5632, Validation Loss: 0.9800, Validation Accuracy: 0.5532, Validation F1: 0.5226\n",
            "0.543950177935943\n",
            "\n",
            " Epoch [13/20], Train Loss: 0.5622, Validation Loss: 0.9843, Validation Accuracy: 0.5440, Validation F1: 0.5165\n",
            "0.545017793594306\n",
            "\n",
            " Epoch [14/20], Train Loss: 0.5611, Validation Loss: 0.9828, Validation Accuracy: 0.5450, Validation F1: 0.5101\n",
            "0.5462633451957295\n",
            "\n",
            " Epoch [15/20], Train Loss: 0.5608, Validation Loss: 0.9843, Validation Accuracy: 0.5463, Validation F1: 0.5158\n",
            "0.5441281138790035\n",
            "\n",
            " Epoch [16/20], Train Loss: 0.5604, Validation Loss: 0.9868, Validation Accuracy: 0.5441, Validation F1: 0.5075\n",
            "0.5409252669039146\n",
            "\n",
            " Epoch [17/20], Train Loss: 0.5598, Validation Loss: 0.9868, Validation Accuracy: 0.5409, Validation F1: 0.5117\n",
            "0.5419928825622776\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.5599, Validation Loss: 0.9881, Validation Accuracy: 0.5420, Validation F1: 0.5163\n",
            "0.5355871886120996\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.5593, Validation Loss: 0.9919, Validation Accuracy: 0.5356, Validation F1: 0.5111\n",
            "0.5391459074733096\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.5591, Validation Loss: 0.9903, Validation Accuracy: 0.5391, Validation F1: 0.5167\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 800, 'dropout': 0.6, 'lr': 0.0001}\n",
            "0.4188612099644128\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.1082, Validation Loss: 1.0586, Validation Accuracy: 0.4189, Validation F1: 0.2590\n",
            "0.49537366548042705\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0362, Validation Loss: 1.0259, Validation Accuracy: 0.4954, Validation F1: 0.3615\n",
            "0.5078291814946619\n",
            "\n",
            " Epoch [3/20], Train Loss: 0.9998, Validation Loss: 1.0150, Validation Accuracy: 0.5078, Validation F1: 0.3727\n",
            "0.5122775800711744\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.9756, Validation Loss: 1.0092, Validation Accuracy: 0.5123, Validation F1: 0.3772\n",
            "0.5169039145907474\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9522, Validation Loss: 1.0052, Validation Accuracy: 0.5169, Validation F1: 0.3807\n",
            "0.5227758007117438\n",
            "\n",
            " Epoch [6/20], Train Loss: 0.9361, Validation Loss: 1.0021, Validation Accuracy: 0.5228, Validation F1: 0.3850\n",
            "0.5240213523131673\n",
            "\n",
            " Epoch [7/20], Train Loss: 0.9207, Validation Loss: 0.9995, Validation Accuracy: 0.5240, Validation F1: 0.3859\n",
            "0.5309608540925267\n",
            "\n",
            " Epoch [8/20], Train Loss: 0.9070, Validation Loss: 0.9975, Validation Accuracy: 0.5310, Validation F1: 0.3911\n",
            "0.5298932384341637\n",
            "\n",
            " Epoch [9/20], Train Loss: 0.8910, Validation Loss: 0.9954, Validation Accuracy: 0.5299, Validation F1: 0.3903\n",
            "0.5336298932384341\n",
            "\n",
            " Epoch [10/20], Train Loss: 0.8756, Validation Loss: 0.9935, Validation Accuracy: 0.5336, Validation F1: 0.3931\n",
            "0.5320284697508897\n",
            "\n",
            " Epoch [11/20], Train Loss: 0.8658, Validation Loss: 0.9928, Validation Accuracy: 0.5320, Validation F1: 0.3918\n",
            "0.5357651245551601\n",
            "\n",
            " Epoch [12/20], Train Loss: 0.8556, Validation Loss: 0.9910, Validation Accuracy: 0.5358, Validation F1: 0.3947\n",
            "0.5375444839857652\n",
            "\n",
            " Epoch [13/20], Train Loss: 0.8409, Validation Loss: 0.9897, Validation Accuracy: 0.5375, Validation F1: 0.3960\n",
            "0.5386120996441282\n",
            "\n",
            " Epoch [14/20], Train Loss: 0.8294, Validation Loss: 0.9892, Validation Accuracy: 0.5386, Validation F1: 0.3968\n",
            "0.5364768683274022\n",
            "\n",
            " Epoch [15/20], Train Loss: 0.8212, Validation Loss: 0.9886, Validation Accuracy: 0.5365, Validation F1: 0.3952\n",
            "0.5361209964412811\n",
            "\n",
            " Epoch [16/20], Train Loss: 0.8104, Validation Loss: 0.9879, Validation Accuracy: 0.5361, Validation F1: 0.3949\n",
            "0.5373665480427047\n",
            "\n",
            " Epoch [17/20], Train Loss: 0.8027, Validation Loss: 0.9875, Validation Accuracy: 0.5374, Validation F1: 0.3958\n",
            "0.5368327402135231\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.7959, Validation Loss: 0.9879, Validation Accuracy: 0.5368, Validation F1: 0.3955\n",
            "0.5379003558718861\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.7854, Validation Loss: 0.9870, Validation Accuracy: 0.5379, Validation F1: 0.3962\n",
            "0.5361209964412811\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.7808, Validation Loss: 0.9872, Validation Accuracy: 0.5361, Validation F1: 0.3949\n",
            "new config\n",
            "{'kernel_sizes': [3, 4, 5], 'embedding_dim': 700, 'dropout': 0.6, 'lr': 0.1}\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.1266, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [5/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "0.38540925266903914\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.1262, Validation Loss: 1.1661, Validation Accuracy: 0.3854, Validation F1: 0.1855\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 500, 'dropout': 0.4, 'lr': 0.0001}\n",
            "0.46512455516014234\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0501, Validation Loss: 1.0394, Validation Accuracy: 0.4651, Validation F1: 0.3375\n",
            "0.4875444839857651\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0084, Validation Loss: 1.0264, Validation Accuracy: 0.4875, Validation F1: 0.3582\n",
            "0.501423487544484\n",
            "\n",
            " Epoch [3/20], Train Loss: 0.9744, Validation Loss: 1.0184, Validation Accuracy: 0.5014, Validation F1: 0.3690\n",
            "0.5048042704626334\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.9538, Validation Loss: 1.0128, Validation Accuracy: 0.5048, Validation F1: 0.3715\n",
            "0.5092526690391459\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9344, Validation Loss: 1.0094, Validation Accuracy: 0.5093, Validation F1: 0.3745\n",
            "0.5161921708185053\n",
            "\n",
            " Epoch [6/20], Train Loss: 0.9173, Validation Loss: 1.0051, Validation Accuracy: 0.5162, Validation F1: 0.3798\n",
            "0.5213523131672598\n",
            "\n",
            " Epoch [7/20], Train Loss: 0.8979, Validation Loss: 1.0022, Validation Accuracy: 0.5214, Validation F1: 0.3836\n",
            "0.5240213523131673\n",
            "\n",
            " Epoch [8/20], Train Loss: 0.8830, Validation Loss: 0.9998, Validation Accuracy: 0.5240, Validation F1: 0.3854\n",
            "0.5281138790035588\n",
            "\n",
            " Epoch [9/20], Train Loss: 0.8693, Validation Loss: 0.9978, Validation Accuracy: 0.5281, Validation F1: 0.3884\n",
            "0.5282918149466193\n",
            "\n",
            " Epoch [10/20], Train Loss: 0.8543, Validation Loss: 0.9961, Validation Accuracy: 0.5283, Validation F1: 0.3883\n",
            "0.5320284697508897\n",
            "\n",
            " Epoch [11/20], Train Loss: 0.8441, Validation Loss: 0.9942, Validation Accuracy: 0.5320, Validation F1: 0.3913\n",
            "0.5325622775800711\n",
            "\n",
            " Epoch [12/20], Train Loss: 0.8280, Validation Loss: 0.9927, Validation Accuracy: 0.5326, Validation F1: 0.3916\n",
            "0.5357651245551601\n",
            "\n",
            " Epoch [13/20], Train Loss: 0.8172, Validation Loss: 0.9917, Validation Accuracy: 0.5358, Validation F1: 0.3940\n",
            "0.5366548042704626\n",
            "\n",
            " Epoch [14/20], Train Loss: 0.8085, Validation Loss: 0.9904, Validation Accuracy: 0.5367, Validation F1: 0.3950\n",
            "0.5359430604982206\n",
            "\n",
            " Epoch [15/20], Train Loss: 0.7992, Validation Loss: 0.9905, Validation Accuracy: 0.5359, Validation F1: 0.3940\n",
            "0.5393238434163701\n",
            "\n",
            " Epoch [16/20], Train Loss: 0.7886, Validation Loss: 0.9894, Validation Accuracy: 0.5393, Validation F1: 0.3970\n",
            "0.5387900355871886\n",
            "\n",
            " Epoch [17/20], Train Loss: 0.7806, Validation Loss: 0.9893, Validation Accuracy: 0.5388, Validation F1: 0.3965\n",
            "0.5384341637010677\n",
            "\n",
            " Epoch [18/20], Train Loss: 0.7720, Validation Loss: 0.9889, Validation Accuracy: 0.5384, Validation F1: 0.3962\n",
            "0.5362989323843417\n",
            "\n",
            " Epoch [19/20], Train Loss: 0.7671, Validation Loss: 0.9894, Validation Accuracy: 0.5363, Validation F1: 0.3946\n",
            "0.5377224199288256\n",
            "\n",
            " Epoch [20/20], Train Loss: 0.7587, Validation Loss: 0.9891, Validation Accuracy: 0.5377, Validation F1: 0.3957\n",
            "new config\n",
            "{'kernel_sizes': [1, 2, 3], 'embedding_dim': 600, 'dropout': 0.6, 'lr': 0.01}\n",
            "0.5080071174377224\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0037, Validation Loss: 1.0430, Validation Accuracy: 0.5080, Validation F1: 0.3724\n",
            "0.4663701067615658\n",
            "\n",
            " Epoch [2/20], Train Loss: 0.9915, Validation Loss: 1.0844, Validation Accuracy: 0.4664, Validation F1: 0.3039\n",
            "0.506405693950178\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0000, Validation Loss: 1.0447, Validation Accuracy: 0.5064, Validation F1: 0.3727\n",
            "0.5019572953736655\n",
            "\n",
            " Epoch [4/20], Train Loss: 0.9922, Validation Loss: 1.0492, Validation Accuracy: 0.5020, Validation F1: 0.3691\n",
            "0.49537366548042705\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9989, Validation Loss: 1.0557, Validation Accuracy: 0.4954, Validation F1: 0.3631\n",
            "0.5030249110320285\n",
            "\n",
            " Epoch [6/20], Train Loss: 1.0030, Validation Loss: 1.0484, Validation Accuracy: 0.5030, Validation F1: 0.3630\n",
            "0.4501779359430605\n",
            "\n",
            " Epoch [7/20], Train Loss: 1.0198, Validation Loss: 1.1014, Validation Accuracy: 0.4502, Validation F1: 0.2981\n",
            "0.504270462633452\n",
            "\n",
            " Epoch [8/20], Train Loss: 1.0271, Validation Loss: 1.0473, Validation Accuracy: 0.5043, Validation F1: 0.3709\n",
            "0.5019572953736655\n",
            "\n",
            " Epoch [9/20], Train Loss: 1.0033, Validation Loss: 1.0496, Validation Accuracy: 0.5020, Validation F1: 0.3679\n",
            "0.40373665480427046\n",
            "\n",
            " Epoch [10/20], Train Loss: 1.0779, Validation Loss: 1.1479, Validation Accuracy: 0.4037, Validation F1: 0.2247\n",
            "0.497153024911032\n",
            "\n",
            " Epoch [11/20], Train Loss: 1.0508, Validation Loss: 1.0542, Validation Accuracy: 0.4972, Validation F1: 0.3634\n",
            "0.47758007117437723\n",
            "\n",
            " Epoch [12/20], Train Loss: 1.0363, Validation Loss: 1.0740, Validation Accuracy: 0.4776, Validation F1: 0.3394\n",
            "0.4597864768683274\n",
            "\n",
            " Epoch [13/20], Train Loss: 1.0234, Validation Loss: 1.0916, Validation Accuracy: 0.4598, Validation F1: 0.2981\n",
            "0.43896797153024913\n",
            "\n",
            " Epoch [14/20], Train Loss: 1.0451, Validation Loss: 1.1125, Validation Accuracy: 0.4390, Validation F1: 0.2434\n",
            "0.4322064056939502\n",
            "\n",
            " Epoch [15/20], Train Loss: 1.0999, Validation Loss: 1.1192, Validation Accuracy: 0.4322, Validation F1: 0.2307\n",
            "0.4653024911032028\n",
            "\n",
            " Epoch [16/20], Train Loss: 1.0521, Validation Loss: 1.0861, Validation Accuracy: 0.4653, Validation F1: 0.3118\n",
            "0.48558718861209965\n",
            "\n",
            " Epoch [17/20], Train Loss: 1.0327, Validation Loss: 1.0659, Validation Accuracy: 0.4856, Validation F1: 0.3451\n",
            "0.48612099644128115\n",
            "\n",
            " Epoch [18/20], Train Loss: 1.0298, Validation Loss: 1.0653, Validation Accuracy: 0.4861, Validation F1: 0.3456\n",
            "0.4889679715302491\n",
            "\n",
            " Epoch [19/20], Train Loss: 1.0064, Validation Loss: 1.0625, Validation Accuracy: 0.4890, Validation F1: 0.3597\n",
            "0.49483985765124555\n",
            "\n",
            " Epoch [20/20], Train Loss: 1.0012, Validation Loss: 1.0565, Validation Accuracy: 0.4948, Validation F1: 0.3615\n",
            "new config\n",
            "{'kernel_sizes': [1, 4, 6], 'embedding_dim': 800, 'dropout': 0.7, 'lr': 0.0001}\n",
            "0.453914590747331\n",
            "\n",
            " Epoch [1/20], Train Loss: 1.0830, Validation Loss: 1.0470, Validation Accuracy: 0.4539, Validation F1: 0.3111\n",
            "0.4903914590747331\n",
            "\n",
            " Epoch [2/20], Train Loss: 1.0413, Validation Loss: 1.0254, Validation Accuracy: 0.4904, Validation F1: 0.3596\n",
            "0.49697508896797155\n",
            "\n",
            " Epoch [3/20], Train Loss: 1.0167, Validation Loss: 1.0179, Validation Accuracy: 0.4970, Validation F1: 0.3652\n",
            "0.506405693950178\n",
            "\n",
            " Epoch [4/20], Train Loss: 1.0003, Validation Loss: 1.0132, Validation Accuracy: 0.5064, Validation F1: 0.3725\n",
            "0.5072953736654804\n",
            "\n",
            " Epoch [5/20], Train Loss: 0.9803, Validation Loss: 1.0097, Validation Accuracy: 0.5073, Validation F1: 0.3733\n",
            "0.5115658362989324\n",
            "\n",
            " Epoch [6/20], Train Loss: 0.9670, Validation Loss: 1.0075, Validation Accuracy: 0.5116, Validation F1: 0.3762\n",
            "0.5161921708185053\n",
            "\n",
            " Epoch [7/20], Train Loss: 0.9547, Validation Loss: 1.0044, Validation Accuracy: 0.5162, Validation F1: 0.3799\n",
            "0.5158362989323844\n",
            "\n",
            " Epoch [8/20], Train Loss: 0.9401, Validation Loss: 1.0015, Validation Accuracy: 0.5158, Validation F1: 0.3798\n",
            "0.5209964412811388\n",
            "\n",
            " Epoch [9/20], Train Loss: 0.9243, Validation Loss: 0.9994, Validation Accuracy: 0.5210, Validation F1: 0.3836\n",
            "0.5231316725978647\n",
            "\n",
            " Epoch [10/20], Train Loss: 0.9155, Validation Loss: 0.9976, Validation Accuracy: 0.5231, Validation F1: 0.3852\n",
            "0.5266903914590747\n",
            "\n",
            " Epoch [11/20], Train Loss: 0.9050, Validation Loss: 0.9956, Validation Accuracy: 0.5267, Validation F1: 0.3878\n"
          ]
        }
      ],
      "source": [
        "random_search(30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {'kernel_sizes': [1, 4, 6], 'embedding_dim': 400, 'dropout': 0.2, 'lr': 0.001}\n"
      ],
      "metadata": {
        "id": "9t4bXaqkkiDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F8gr3Rk6lXIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}